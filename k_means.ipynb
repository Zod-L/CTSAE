{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, rand_score\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from munkres import Munkres\n",
    "from scipy.special import comb\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "\n",
    "\n",
    "def map_label(pred, gt):\n",
    "    \"\"\"entry point\"\"\"\n",
    "\n",
    "    num_labels = len(np.unique(gt))\n",
    "\n",
    "    # cm = confusion_matrix(gt, pred, labels=range(num_labels)) # gets the confusion matrix\n",
    "\n",
    "    cost_matrix = make_cost_matrix(pred, gt)\n",
    "\n",
    "    m = Munkres()\n",
    "    indexes = m.compute(cost_matrix)\n",
    "    mapper = { old: new for (old, new) in indexes }\n",
    "\n",
    "\n",
    "    new_labels = translate_clustering(pred, mapper)\n",
    "    new_cm = confusion_matrix(gt, new_labels, labels=range(num_labels))\n",
    "    return new_labels, mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_vote(nn_class, labels, k):\n",
    "    cur = 0\n",
    "    for i in range(nn_class.shape[0]):\n",
    "        max_num = 0\n",
    "        for j in range(k):\n",
    "            if ((nn_class[i, :] == nn_class[i, j]).sum() > max_num) or \\\n",
    "            (k > 1 and (nn_class[i, :] == nn_class[i, j]).sum() == max_num and nn_class[i, j] != labels[i]):\n",
    "                max_num = (nn_class[i, :] == nn_class[i, j]).sum()\n",
    "                max_class = nn_class[i, j]\n",
    "        \n",
    "        if max_class == labels[i]:\n",
    "            cur += 1\n",
    "    return cur\n",
    "\n",
    "\n",
    "def mean_average_precision(index, label):\n",
    "    correct = (index == label[:, None]).astype(np.int32)\n",
    "    precision = np.cumsum(correct, 1) / (np.arange(index.shape[1])[None, :] + 1)\n",
    "    res = (precision * correct).sum(1) / (correct.sum(1) + 1e-6)\n",
    "    return res.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_code/cnn_share_attn/val\n",
      "\n",
      "latent_code/cnn_share_attn/test\n",
      "\n",
      "latent_code/cnn_split_attn/val\n",
      "\n",
      "latent_code/cnn_split_attn/test\n",
      "\n",
      "latent_code/cnn/val\n",
      "\n",
      "latent_code/cnn/test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "for model_dir in os.listdir(\"latent_code\"):\n",
    "    all_data[model_dir] = {}\n",
    "    for s in [\"val\", \"test\"]:\n",
    "        test_dir = os.path.join(\"latent_code\", model_dir, s)\n",
    "\n",
    "        num_test = len(os.listdir(test_dir)) // 2\n",
    "\n",
    "        classes = [dir for dir in os.listdir(f\"{test_dir}/test_0\")]\n",
    "        classes.sort()\n",
    "        print(test_dir)\n",
    "        print()\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "        fnames = []\n",
    "\n",
    "        idx_num = [int(fname.split(\"_\")[-1]) for fname in os.listdir(f\"{test_dir}\") if \"im\" not in fname]\n",
    "        idx_num.sort()\n",
    "        num_file = 0\n",
    "        for i, dir in enumerate(classes):\n",
    "            _dir = os.path.join(f\"{test_dir}/test_0\")\n",
    "            for fname in os.listdir(os.path.join(_dir, dir)):\n",
    "                num_file += 1\n",
    "\n",
    "\n",
    "        shuffle_idx = np.arange(num_file)\n",
    "        np.random.shuffle(shuffle_idx)\n",
    "\n",
    "\n",
    "\n",
    "        for idx in idx_num:\n",
    "            data_tmp = []\n",
    "            label_tmp = []\n",
    "            fnames_tmp = []\n",
    "            for i, dir in enumerate(classes):\n",
    "                _dir = os.path.join(f\"{test_dir}/test_{idx}\")\n",
    "                for fname in os.listdir(os.path.join(_dir, dir)):\n",
    "                    data_tmp.append(np.load(os.path.join(_dir, dir, fname)))\n",
    "                    label_tmp.append(i)\n",
    "                    fnames_tmp.append(os.path.join(_dir, dir, fname))\n",
    "\n",
    "            data.append(np.vstack(data_tmp)[shuffle_idx, :])\n",
    "            labels.append(np.array(label_tmp)[shuffle_idx])\n",
    "            fnames.append(np.array(fnames_tmp)[shuffle_idx])\n",
    "        all_data[model_dir][s] = dict(data=data, labels=labels, fnames=fnames, idx_num=idx_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn_share_attn-val================================================\n",
      "         Top1_0    Top3_0    Top5_0    Top7_0   Top10_0   Top1_10   Top3_10  \\\n",
      "total  0.349964  0.279923  0.342048  0.345646  0.372511  0.722955  0.720556   \n",
      "\n",
      "        Top5_10   Top7_10  Top10_10   Top1_20   Top3_20   Top5_20   Top7_20  \\\n",
      "total  0.727273  0.730871  0.727513  0.769729  0.762053  0.769489  0.772367   \n",
      "\n",
      "       Top10_20   Top1_40   Top3_40   Top5_40   Top7_40  Top10_40   Top1_60  \\\n",
      "total  0.761574  0.760614  0.754378  0.755817  0.761094  0.744303  0.727273   \n",
      "\n",
      "        Top3_60   Top5_60   Top7_60  Top10_60   Top1_80   Top3_80   Top5_80  \\\n",
      "total  0.712641  0.718158  0.718877  0.712641  0.720796  0.707604  0.712161   \n",
      "\n",
      "        Top7_80  Top10_80  Top1_100  Top3_100  Top5_100  Top7_100  Top10_100  \\\n",
      "total  0.710482  0.700168  0.712401  0.707844  0.701607  0.703766    0.69609   \n",
      "\n",
      "       Top1_120  Top3_120  Top5_120  Top7_120  Top10_120  Top1_140  Top3_140  \\\n",
      "total  0.723675  0.710002  0.713361  0.720556   0.702806   0.71408  0.705685   \n",
      "\n",
      "       Top5_140  Top7_140  Top10_140  Top1_160  Top3_160  Top5_160  Top7_160  \\\n",
      "total  0.702327  0.706884    0.69705   0.71504  0.706404  0.702806  0.712401   \n",
      "\n",
      "       Top10_160  Top1_180  Top3_180  Top5_180  Top7_180  Top10_180  Top1_200  \\\n",
      "total    0.69705  0.719117  0.712641  0.716959  0.719837   0.708563   0.71408   \n",
      "\n",
      "       Top3_200  Top5_200  Top7_200  Top10_200  Top1_220  Top3_220  Top5_220  \\\n",
      "total  0.709763   0.71456  0.717918   0.709763  0.717438  0.711202  0.713121   \n",
      "\n",
      "       Top7_220  Top10_220  Top1_240  Top3_240  Top5_240  Top7_240  Top10_240  \\\n",
      "total  0.715759   0.710242  0.720317  0.717678  0.721036  0.721036   0.711681   \n",
      "\n",
      "       Top1_260  Top3_260  Top5_260  Top7_260  Top10_260  Top1_280  Top3_280  \\\n",
      "total  0.723195  0.709523    0.7148  0.719597   0.712161  0.719837    0.7136   \n",
      "\n",
      "       Top5_280  Top7_280  Top10_280  Top1_300  Top3_300  Top5_300  Top7_300  \\\n",
      "total  0.711202  0.722715   0.710722  0.721756  0.710962   0.71456  0.718158   \n",
      "\n",
      "       Top10_300  \n",
      "total   0.708803  \n",
      "=============================cnn_share_attn-test================================================\n",
      "         Top1_0    Top3_0    Top5_0    Top7_0   Top10_0  Top1_10   Top3_10  \\\n",
      "total  0.341607  0.276619  0.338249  0.353837  0.379257  0.73717  0.741607   \n",
      "\n",
      "        Top5_10   Top7_10  Top10_10   Top1_20   Top3_20   Top5_20   Top7_20  \\\n",
      "total  0.741607  0.748201  0.742806  0.780216  0.781535  0.788489  0.792206   \n",
      "\n",
      "       Top10_20   Top1_40  Top3_40   Top5_40  Top7_40  Top10_40   Top1_60  \\\n",
      "total  0.786571  0.764269  0.76295  0.772182  0.77446  0.763189  0.727818   \n",
      "\n",
      "        Top3_60   Top5_60   Top7_60  Top10_60   Top1_80   Top3_80   Top5_80  \\\n",
      "total  0.733933  0.738969  0.747362  0.739688  0.728058  0.726379  0.730935   \n",
      "\n",
      "       Top7_80  Top10_80  Top1_100  Top3_100  Top5_100  Top7_100  Top10_100  \\\n",
      "total  0.73801  0.729376  0.722662  0.721942  0.729257  0.736091   0.727218   \n",
      "\n",
      "       Top1_120  Top3_120  Top5_120  Top7_120  Top10_120  Top1_140  Top3_140  \\\n",
      "total  0.735012  0.731055  0.734532  0.745444    0.73753  0.721823  0.723141   \n",
      "\n",
      "       Top5_140  Top7_140  Top10_140  Top1_160  Top3_160  Top5_160  Top7_160  \\\n",
      "total  0.722422  0.734772   0.724221  0.720144  0.721223  0.723501   0.73801   \n",
      "\n",
      "       Top10_160  Top1_180  Top3_180  Top5_180  Top7_180  Top10_180  Top1_200  \\\n",
      "total    0.72494  0.735252  0.734293   0.73789  0.745803   0.730096  0.723141   \n",
      "\n",
      "       Top3_200  Top5_200  Top7_200  Top10_200  Top1_220  Top3_220  Top5_220  \\\n",
      "total   0.72458    0.7253  0.732494   0.726499  0.729976  0.727338  0.732494   \n",
      "\n",
      "       Top7_220  Top10_220  Top1_240  Top3_240  Top5_240  Top7_240  Top10_240  \\\n",
      "total  0.738249   0.729736  0.731894  0.727578   0.73693  0.740288   0.732374   \n",
      "\n",
      "       Top1_260  Top3_260  Top5_260  Top7_260  Top10_260  Top1_280  Top3_280  \\\n",
      "total  0.730216  0.727458  0.733213  0.741247   0.730336  0.733213  0.734053   \n",
      "\n",
      "       Top5_280  Top7_280  Top10_280  Top1_300  Top3_300  Top5_300  Top7_300  \\\n",
      "total  0.736451  0.746643   0.732134  0.731775  0.731535  0.735851  0.740647   \n",
      "\n",
      "       Top10_300  \n",
      "total   0.733333  \n",
      "=============================cnn_split_attn-val================================================\n",
      "         Top1_0    Top3_0    Top5_0    Top7_0   Top10_0   Top1_10   Top3_10  \\\n",
      "total  0.333893  0.271768  0.328376  0.337491  0.361717  0.753898  0.754378   \n",
      "\n",
      "        Top5_10   Top7_10  Top10_10   Top1_20   Top3_20   Top5_20   Top7_20  \\\n",
      "total  0.753418  0.757976  0.754857  0.735428  0.720556  0.718398  0.720317   \n",
      "\n",
      "       Top10_20   Top1_40   Top3_40   Top5_40   Top7_40  Top10_40   Top1_60  \\\n",
      "total  0.712401  0.715279  0.691773  0.692252  0.706165   0.69681  0.703046   \n",
      "\n",
      "       Top3_60   Top5_60   Top7_60  Top10_60   Top1_80   Top3_80   Top5_80  \\\n",
      "total  0.69561  0.693212  0.700168  0.693931  0.701607  0.693212  0.695371   \n",
      "\n",
      "        Top7_80  Top10_80  Top1_100  Top3_100  Top5_100  Top7_100  Top10_100  \\\n",
      "total  0.702327  0.690094  0.699448  0.698009  0.694411  0.705685   0.692012   \n",
      "\n",
      "       Top1_120  Top3_120  Top5_120  Top7_120  Top10_120  Top1_140  Top3_140  \\\n",
      "total  0.699688   0.69561   0.69657  0.704725    0.69561  0.690813  0.695371   \n",
      "\n",
      "       Top5_140  Top7_140  Top10_140  \n",
      "total  0.700648  0.707604   0.692732  \n",
      "=============================cnn_split_attn-test================================================\n",
      "         Top1_0    Top3_0    Top5_0    Top7_0   Top10_0   Top1_10   Top3_10  \\\n",
      "total  0.347962  0.278537  0.330096  0.341966  0.367626  0.769305  0.768945   \n",
      "\n",
      "        Top5_10   Top7_10  Top10_10   Top1_20   Top3_20   Top5_20   Top7_20  \\\n",
      "total  0.776139  0.780336   0.77506  0.739448  0.738249  0.739808  0.747962   \n",
      "\n",
      "       Top10_20   Top1_40   Top3_40   Top5_40   Top7_40  Top10_40   Top1_60  \\\n",
      "total  0.743885  0.722422  0.719065  0.718705  0.733813  0.720863  0.724221   \n",
      "\n",
      "        Top3_60   Top5_60   Top7_60  Top10_60   Top1_80  Top3_80   Top5_80  \\\n",
      "total  0.713669  0.716427  0.726859  0.716427  0.722182  0.71247  0.716187   \n",
      "\n",
      "        Top7_80  Top10_80  Top1_100  Top3_100  Top5_100  Top7_100  Top10_100  \\\n",
      "total  0.723741  0.710911  0.719784  0.713309   0.71271  0.718945   0.711751   \n",
      "\n",
      "       Top1_120  Top3_120  Top5_120  Top7_120  Top10_120  Top1_140  Top3_140  \\\n",
      "total  0.722182  0.709592  0.715588  0.721942   0.713429  0.723861  0.711151   \n",
      "\n",
      "       Top5_140  Top7_140  Top10_140  \n",
      "total  0.714508   0.72542   0.711511  \n",
      "=============================cnn-val================================================\n",
      "         Top1_0    Top3_0   Top5_0    Top7_0   Top10_0  Top1_10   Top3_10  \\\n",
      "total  0.491005  0.465339  0.49988  0.505877  0.519309  0.78604  0.782202   \n",
      "\n",
      "        Top5_10  Top7_10  Top10_10   Top1_20   Top3_20  Top5_20   Top7_20  \\\n",
      "total  0.783881  0.78628  0.776925  0.734709  0.728952  0.73207  0.733989   \n",
      "\n",
      "       Top10_20   Top1_40   Top3_40   Top5_40   Top7_40  Top10_40  Top1_60  \\\n",
      "total  0.722236  0.711681  0.693692  0.693452  0.700648   0.69681  0.69729   \n",
      "\n",
      "        Top3_60   Top5_60  Top7_60  Top10_60   Top1_80   Top3_80   Top5_80  \\\n",
      "total  0.686256  0.688175  0.69633  0.684577  0.694891  0.688414  0.687695   \n",
      "\n",
      "        Top7_80  Top10_80  Top1_100  Top3_100  Top5_100  Top7_100  Top10_100  \\\n",
      "total  0.688894  0.680739  0.692492  0.682898  0.684817  0.683137   0.677381   \n",
      "\n",
      "       Top1_120  Top3_120  Top5_120  Top7_120  Top10_120  Top1_140  Top3_140  \\\n",
      "total  0.686735    0.6793  0.686496  0.693692   0.682418  0.682898  0.677621   \n",
      "\n",
      "       Top5_140  Top7_140  Top10_140  Top1_160  Top3_160  Top5_160  Top7_160  \\\n",
      "total  0.679539  0.691533   0.682178  0.683377  0.675222  0.681219  0.685536   \n",
      "\n",
      "       Top10_160  Top1_180  Top3_180  Top5_180  Top7_180  Top10_180  Top1_200  \\\n",
      "total   0.680019  0.684817  0.679779  0.684817  0.691533   0.681458  0.681938   \n",
      "\n",
      "       Top3_200  Top5_200  Top7_200  Top10_200  \n",
      "total  0.674502   0.67906  0.684337   0.674502  \n",
      "=============================cnn-test================================================\n",
      "         Top1_0    Top3_0    Top5_0   Top7_0   Top10_0   Top1_10   Top3_10  \\\n",
      "total  0.505036  0.480096  0.501199  0.51211  0.527938  0.788849  0.792926   \n",
      "\n",
      "        Top5_10   Top7_10  Top10_10   Top1_20   Top3_20   Top5_20  Top7_20  \\\n",
      "total  0.796882  0.797002  0.793405  0.747842  0.740767  0.745444  0.74964   \n",
      "\n",
      "       Top10_20   Top1_40  Top3_40   Top5_40   Top7_40  Top10_40   Top1_60  \\\n",
      "total  0.744005  0.726259  0.71211  0.714508  0.726619  0.720504  0.711151   \n",
      "\n",
      "        Top3_60   Top5_60   Top7_60  Top10_60   Top1_80   Top3_80   Top5_80  \\\n",
      "total  0.704556  0.706235  0.717266  0.705755  0.707914  0.699161  0.702638   \n",
      "\n",
      "       Top7_80  Top10_80  Top1_100  Top3_100  Top5_100  Top7_100  Top10_100  \\\n",
      "total  0.71235  0.703597  0.708153  0.703957  0.705516  0.709712    0.70036   \n",
      "\n",
      "       Top1_120  Top3_120  Top5_120  Top7_120  Top10_120  Top1_140  Top3_140  \\\n",
      "total  0.705156  0.701799  0.705036  0.715348   0.703477  0.703597  0.697122   \n",
      "\n",
      "       Top5_140  Top7_140  Top10_140  Top1_160  Top3_160  Top5_160  Top7_160  \\\n",
      "total  0.702398  0.707314   0.696882  0.699281  0.696523  0.698321  0.702158   \n",
      "\n",
      "       Top10_160  Top1_180  Top3_180  Top5_180  Top7_180  Top10_180  Top1_200  \\\n",
      "total   0.694365  0.703597       0.7  0.704197  0.708393   0.699281  0.705156   \n",
      "\n",
      "       Top3_200  Top5_200  Top7_200  Top10_200  \n",
      "total  0.697002  0.702038  0.710312   0.701079  \n"
     ]
    }
   ],
   "source": [
    "for m in all_data.keys():\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "\n",
    "            for k in ks:\n",
    "\n",
    "                index = indices[:, :k]\n",
    "                nn_class = labels[idx][index]\n",
    "                acc = []\n",
    "                \n",
    "                for c in range(len(classes)):\n",
    "                    cur = 0\n",
    "                    mask = (labels[idx] == c)\n",
    "                    nn_class_msk = nn_class[mask]\n",
    "                    cur = most_vote(nn_class_msk, labels[idx][mask], k)\n",
    "                    \n",
    "                    acc.append(cur / nn_class_msk.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                total_acc = most_vote(nn_class, labels[idx], k) / nn_class.shape[0]\n",
    "\n",
    "\n",
    "                # show_data[f\"Top{k}_{num}\"] =  acc + [total_acc] \n",
    "                show_data[f\"Top{k}_{num}\"] =  [total_acc] \n",
    "\n",
    "\n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "        # df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "        df = pd.DataFrame(data=show_data, index=[\"total\"])\n",
    "\n",
    "        with pd.option_context(\n",
    "                            'display.max_columns', None,\n",
    "                            ):\n",
    "            print(df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn_share_attn-val================================================\n",
      "          mAP_0    mAP_10    mAP_20    mAP_40    mAP_60    mAP_80   mAP_100  \\\n",
      "total  0.438644  0.758745  0.794347  0.785209  0.750883  0.749034  0.742541   \n",
      "\n",
      "       mAP_120  mAP_140   mAP_160   mAP_180   mAP_200   mAP_220  mAP_240  \\\n",
      "total  0.75038  0.74029  0.739723  0.746478  0.741855  0.743439  0.74582   \n",
      "\n",
      "        mAP_260   mAP_280   mAP_300  \n",
      "total  0.745097  0.746352  0.745508  \n",
      "=============================cnn_share_attn-test================================================\n",
      "          mAP_0    mAP_10    mAP_20    mAP_40    mAP_60    mAP_80   mAP_100  \\\n",
      "total  0.442732  0.773245  0.807204  0.794759  0.765211  0.760808  0.756254   \n",
      "\n",
      "        mAP_120   mAP_140   mAP_160   mAP_180   mAP_200   mAP_220   mAP_240  \\\n",
      "total  0.763001  0.752644  0.753162  0.761451  0.754167  0.758547  0.759436   \n",
      "\n",
      "        mAP_260   mAP_280   mAP_300  \n",
      "total  0.758729  0.762895  0.760188  \n",
      "=============================cnn_split_attn-val================================================\n",
      "          mAP_0    mAP_10    mAP_20    mAP_40    mAP_60    mAP_80   mAP_100  \\\n",
      "total  0.427438  0.784775  0.760907  0.742011  0.737158  0.735218  0.734769   \n",
      "\n",
      "        mAP_120   mAP_140  \n",
      "total  0.734084  0.730952  \n",
      "=============================cnn_split_attn-test================================================\n",
      "          mAP_0    mAP_10    mAP_20    mAP_40    mAP_60    mAP_80   mAP_100  \\\n",
      "total  0.440743  0.797459  0.772386  0.753872  0.750678  0.747252  0.746626   \n",
      "\n",
      "        mAP_120   mAP_140  \n",
      "total  0.747226  0.747398  \n",
      "=============================cnn-val================================================\n",
      "          mAP_0    mAP_10    mAP_20    mAP_40    mAP_60    mAP_80   mAP_100  \\\n",
      "total  0.562286  0.806557  0.763926  0.737759  0.727211  0.724302  0.724665   \n",
      "\n",
      "        mAP_120   mAP_140   mAP_160   mAP_180   mAP_200  \n",
      "total  0.722477  0.720352  0.717085  0.719464  0.718865  \n",
      "=============================cnn-test================================================\n",
      "          mAP_0    mAP_10    mAP_20    mAP_40    mAP_60    mAP_80   mAP_100  \\\n",
      "total  0.572765  0.815378  0.774873  0.750443  0.741364  0.738706  0.739291   \n",
      "\n",
      "        mAP_120   mAP_140   mAP_160   mAP_180  mAP_200  \n",
      "total  0.739238  0.736196  0.734198  0.736799  0.73615  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for m in all_data.keys():\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            \n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "\n",
    "            nn_class = labels[idx][indices]\n",
    "            acc = []\n",
    "            \n",
    "            for c in range(len(classes)):\n",
    "                mask = (labels[idx] == c)\n",
    "                nn_class_msk = nn_class[mask]\n",
    "                cur = mean_average_precision(nn_class_msk, labels[idx][mask])\n",
    "                acc.append(cur)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            total_acc = mean_average_precision(nn_class, labels[idx])\n",
    "\n",
    "\n",
    "            # show_data[f\"mAP_{num}\"] =  acc + [total_acc] \n",
    "            show_data[f\"mAP_{num}\"] =  [total_acc] \n",
    "                \n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "\n",
    "        # df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "        df = pd.DataFrame(data=show_data, index=[\"total\"])\n",
    "\n",
    "        with pd.option_context(\n",
    "                            'display.max_columns', None,\n",
    "                            ):\n",
    "            print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn_share_attn-val================================================\n",
      "                 0     10     20     40     60     80    100    120    140  \\\n",
      "precision     0.30   0.53   0.50   0.44   0.48   0.45   0.48   0.46   0.47   \n",
      "recall        0.19   0.22   0.32   0.37   0.37   0.37   0.35   0.40   0.40   \n",
      "accuracy      0.88   0.85   0.91   0.92   0.92   0.92   0.91   0.93   0.93   \n",
      "adjusted RI   0.17   0.24   0.34   0.36   0.37   0.36   0.36   0.39   0.40   \n",
      "nmi           0.39   0.52   0.60   0.60   0.61   0.59   0.62   0.62   0.63   \n",
      "\n",
      "               160    180    200    220    240    260    280    300  \n",
      "precision     0.47   0.45   0.48   0.41   0.41   0.44   0.44   0.44  \n",
      "recall        0.39   0.42   0.44   0.41   0.35   0.41   0.37   0.41  \n",
      "accuracy      0.92   0.93   0.93   0.93   0.92   0.93   0.92   0.93  \n",
      "adjusted RI   0.39   0.40   0.42   0.37   0.34   0.39   0.36   0.39  \n",
      "nmi           0.63   0.62   0.64   0.61   0.59   0.62   0.59   0.62  \n",
      "=============================cnn_share_attn-test================================================\n",
      "                 0     10     20     40     60     80    100    120    140  \\\n",
      "precision     0.26   0.48   0.47   0.43   0.49   0.41   0.44   0.42   0.42   \n",
      "recall        0.18   0.20   0.32   0.36   0.35   0.29   0.36   0.39   0.41   \n",
      "accuracy      0.89   0.85   0.91   0.92   0.91   0.90   0.92   0.93   0.93   \n",
      "adjusted RI   0.15   0.22   0.33   0.35   0.36   0.29   0.36   0.36   0.37   \n",
      "nmi           0.36   0.51   0.59   0.59   0.61   0.55   0.60   0.61   0.61   \n",
      "\n",
      "               160    180    200    220    240    260    280    300  \n",
      "precision     0.40   0.43   0.49   0.42   0.40   0.41   0.42   0.39  \n",
      "recall        0.39   0.42   0.43   0.45   0.38   0.39   0.39   0.39  \n",
      "accuracy      0.93   0.93   0.93   0.93   0.92   0.92   0.93   0.93  \n",
      "adjusted RI   0.36   0.39   0.42   0.40   0.35   0.36   0.36   0.35  \n",
      "nmi           0.61   0.62   0.63   0.62   0.60   0.60   0.60   0.60  \n",
      "=============================cnn_split_attn-val================================================\n",
      "                 0     10     20     40     60     80    100    120    140\n",
      "precision     0.25   0.53   0.38   0.40   0.41   0.40   0.42   0.41   0.44\n",
      "recall        0.16   0.20   0.33   0.38   0.36   0.37   0.36   0.33   0.37\n",
      "accuracy      0.87   0.84   0.92   0.92   0.92   0.92   0.92   0.91   0.92\n",
      "adjusted RI   0.13   0.22   0.31   0.35   0.34   0.34   0.34   0.32   0.36\n",
      "nmi           0.34   0.52   0.57   0.59   0.60   0.60   0.60   0.58   0.60\n",
      "=============================cnn_split_attn-test================================================\n",
      "                 0     10     20     40     60     80    100    120    140\n",
      "precision     0.26   0.56   0.38   0.39   0.38   0.38   0.36   0.38   0.36\n",
      "recall        0.16   0.22   0.33   0.34   0.35   0.37   0.35   0.35   0.38\n",
      "accuracy      0.87   0.85   0.91   0.92   0.92   0.92   0.92   0.92   0.92\n",
      "adjusted RI   0.13   0.24   0.31   0.32   0.32   0.33   0.31   0.32   0.33\n",
      "nmi           0.35   0.53   0.57   0.58   0.57   0.58   0.57   0.59   0.58\n",
      "=============================cnn-val================================================\n",
      "                 0     10     20     40     60     80    100    120    140  \\\n",
      "precision     0.36   0.49   0.43   0.38   0.38   0.38   0.38   0.39   0.37   \n",
      "recall        0.18   0.26   0.32   0.33   0.36   0.32   0.35   0.36   0.33   \n",
      "accuracy      0.86   0.88   0.91   0.92   0.92   0.91   0.92   0.92   0.92   \n",
      "adjusted RI   0.17   0.28   0.32   0.31   0.33   0.30   0.32   0.33   0.31   \n",
      "nmi           0.43   0.57   0.57   0.57   0.60   0.57   0.59   0.59   0.57   \n",
      "\n",
      "               160    180    200  \n",
      "precision     0.39   0.39   0.39  \n",
      "recall        0.38   0.35   0.31  \n",
      "accuracy      0.92   0.92   0.91  \n",
      "adjusted RI   0.34   0.33   0.30  \n",
      "nmi           0.59   0.59   0.56  \n",
      "=============================cnn-test================================================\n",
      "                 0     10     20     40     60     80    100    120    140  \\\n",
      "precision     0.37   0.47   0.41   0.38   0.39   0.39   0.38   0.38   0.35   \n",
      "recall        0.19   0.30   0.32   0.33   0.29   0.33   0.34   0.35   0.35   \n",
      "accuracy      0.87   0.90   0.91   0.91   0.91   0.91   0.92   0.92   0.92   \n",
      "adjusted RI   0.19   0.32   0.32   0.31   0.29   0.31   0.31   0.32   0.31   \n",
      "nmi           0.44   0.58   0.56   0.57   0.55   0.58   0.57   0.56   0.58   \n",
      "\n",
      "               160    180    200  \n",
      "precision     0.37   0.38   0.35  \n",
      "recall        0.35   0.34   0.34  \n",
      "accuracy      0.92   0.92   0.92  \n",
      "adjusted RI   0.31   0.31   0.30  \n",
      "nmi           0.58   0.58   0.55  \n"
     ]
    }
   ],
   "source": [
    "def confusion(actual, pred):\n",
    "\n",
    "    tp_plus_fp = comb(np.bincount(actual), 2).sum()\n",
    "    tp_plus_fn = comb(np.bincount(pred), 2).sum()\n",
    "    A = np.c_[(actual, pred)]\n",
    "    tp = sum(comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum()\n",
    "             for i in set(actual))\n",
    "    fp = tp_plus_fp - tp\n",
    "    fn = tp_plus_fn - tp\n",
    "    tn = comb(len(A), 2) - tp - fp - fn\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "for m in all_data.keys():\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "            tp, tn, fp, fn = confusion(labels[idx], kmeans.labels_)\n",
    "            total_prec = tp / (tp + fp)\n",
    "            total_rec = tp / (tp + fn)\n",
    "            total_acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "            total_ari = adjusted_rand_score(labels[idx], kmeans.labels_)\n",
    "            total_nmi = normalized_mutual_info_score(labels[idx], kmeans.labels_)\n",
    "\n",
    "            show_data[f\"{num}\"] = [f\"{total_prec : .2f}\", f\"{total_rec : .2f}\", f\"{total_acc : .2f}\", f\"{total_ari : .2f}\", f\"{total_nmi : .2f}\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "        df = pd.DataFrame(data=show_data, index=[\"precision\", \"recall\", \"accuracy\", \"adjusted RI\", \"nmi\"])\n",
    "        with pd.option_context(\n",
    "                            'display.max_columns', None,\n",
    "                            ):\n",
    "            print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           cnn_share_attn-val  cnn_share_attn-test  cnn_split_attn-val  \\\n",
      "Top_1                    0.35                 0.34                0.33   \n",
      "Top_3                    0.38                 0.38                0.36   \n",
      "Top_5                    0.38                 0.38                0.36   \n",
      "Top_7                    0.37                 0.38                0.36   \n",
      "Top_10                   0.37                 0.38                0.36   \n",
      "mean_ap                  0.44                 0.44                0.43   \n",
      "total_ari                0.17                 0.15                0.13   \n",
      "total_nmi                0.39                 0.36                0.34   \n",
      "\n",
      "           cnn_split_attn-test  cnn-val  cnn-test  \n",
      "Top_1                     0.35     0.49      0.51  \n",
      "Top_3                     0.37     0.52      0.54  \n",
      "Top_5                     0.37     0.52      0.53  \n",
      "Top_7                     0.37     0.52      0.53  \n",
      "Top_10                    0.37     0.52      0.53  \n",
      "mean_ap                   0.44     0.56      0.57  \n",
      "total_ari                 0.13     0.17      0.19  \n",
      "total_nmi                 0.35     0.43      0.44  \n"
     ]
    }
   ],
   "source": [
    "best_model = {\"cnn\" : 0, \"cnn_share_attn\" : 0, \"cnn_split_attn\" : 0}\n",
    "show_data = {}\n",
    "\n",
    "\n",
    "\n",
    "for m in all_data.keys():\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            if num != best_model[m]:\n",
    "                continue\n",
    "            \n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "            nn_class = labels[idx][indices]\n",
    "\n",
    "            mean_ap = mean_average_precision(nn_class, labels[idx])\n",
    "            \n",
    "\n",
    "            kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "            tp, tn, fp, fn = confusion(labels[idx], kmeans.labels_)\n",
    "            total_ari = adjusted_rand_score(labels[idx], kmeans.labels_)\n",
    "            total_nmi = normalized_mutual_info_score(labels[idx], kmeans.labels_)\n",
    "\n",
    "\n",
    "\n",
    "            show_data[f\"{m}-{s}\"] = [most_vote(nn_class, labels[idx], k) / nn_class.shape[0] for k in ks] + [mean_ap, total_ari, total_nmi] \n",
    "                \n",
    "\n",
    "\n",
    "pd.set_option(\"display.precision\", 2)\n",
    "df = pd.DataFrame(data=show_data, index=[f\"Top_{k}\" for k in ks] + [\"mean_ap\", \"total_ari\", \"total_nmi\"])\n",
    "\n",
    "with pd.option_context(\n",
    "                    'display.max_columns', None,\n",
    "                    ):\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_share_attn/val/test_im_220 : 0\n",
      "cnn_share_attn/val/test_im_80 : 0\n",
      "cnn_share_attn/val/test_260 : 4169\n",
      "cnn_share_attn/val/test_80 : 4169\n",
      "cnn_share_attn/val/test_im_140 : 0\n",
      "cnn_share_attn/val/test_im_0 : 0\n",
      "cnn_share_attn/val/test_180 : 4169\n",
      "cnn_share_attn/val/test_100 : 4169\n",
      "cnn_share_attn/val/test_300 : 4169\n",
      "cnn_share_attn/val/test_im_120 : 0\n",
      "cnn_share_attn/val/test_0 : 4169\n",
      "cnn_share_attn/val/test_10 : 4169\n",
      "cnn_share_attn/val/test_160 : 4169\n",
      "cnn_share_attn/val/test_im_10 : 0\n",
      "cnn_share_attn/val/test_im_240 : 0\n",
      "cnn_share_attn/val/test_im_60 : 0\n",
      "cnn_share_attn/val/test_280 : 4169\n",
      "cnn_share_attn/val/test_60 : 4169\n",
      "cnn_share_attn/val/test_200 : 4169\n",
      "cnn_share_attn/val/test_im_160 : 0\n",
      "cnn_share_attn/val/test_120 : 4169\n",
      "cnn_share_attn/val/test_im_300 : 0\n",
      "cnn_share_attn/val/test_im_200 : 0\n",
      "cnn_share_attn/val/test_im_20 : 0\n",
      "cnn_share_attn/val/test_20 : 4169\n",
      "cnn_share_attn/val/test_im_280 : 0\n",
      "cnn_share_attn/val/test_240 : 4169\n",
      "cnn_share_attn/val/test_im_40 : 0\n",
      "cnn_share_attn/val/test_40 : 4169\n",
      "cnn_share_attn/val/test_im_260 : 0\n",
      "cnn_share_attn/val/test_220 : 4169\n",
      "cnn_share_attn/val/test_im_100 : 0\n",
      "cnn_share_attn/val/test_im_180 : 0\n",
      "cnn_share_attn/val/test_140 : 4169\n",
      "cnn_share_attn/test/test_im_80 : 0\n",
      "cnn_share_attn/test/test_10 : 8340\n",
      "cnn_share_attn/test/test_im_260 : 0\n",
      "cnn_share_attn/test/test_260 : 8340\n",
      "cnn_share_attn/test/test_im_180 : 0\n",
      "cnn_share_attn/test/test_180 : 8340\n",
      "cnn_share_attn/test/test_60 : 8340\n",
      "cnn_share_attn/test/test_im_100 : 0\n",
      "cnn_share_attn/test/test_100 : 8340\n",
      "cnn_share_attn/test/test_300 : 8340\n",
      "cnn_share_attn/test/test_im_300 : 0\n",
      "cnn_share_attn/test/test_80 : 8340\n",
      "cnn_share_attn/test/test_im_10 : 0\n",
      "cnn_share_attn/test/test_im_0 : 0\n",
      "cnn_share_attn/test/test_im_160 : 0\n",
      "cnn_share_attn/test/test_160 : 8340\n",
      "cnn_share_attn/test/test_0 : 8340\n",
      "cnn_share_attn/test/test_im_280 : 0\n",
      "cnn_share_attn/test/test_280 : 8340\n",
      "cnn_share_attn/test/test_im_60 : 0\n",
      "cnn_share_attn/test/test_im_200 : 0\n",
      "cnn_share_attn/test/test_200 : 8340\n",
      "cnn_share_attn/test/test_40 : 8340\n",
      "cnn_share_attn/test/test_im_120 : 0\n",
      "cnn_share_attn/test/test_120 : 8340\n",
      "cnn_share_attn/test/test_im_20 : 0\n",
      "cnn_share_attn/test/test_im_240 : 0\n",
      "cnn_share_attn/test/test_240 : 8340\n",
      "cnn_share_attn/test/test_im_40 : 0\n",
      "cnn_share_attn/test/test_im_220 : 0\n",
      "cnn_share_attn/test/test_220 : 8340\n",
      "cnn_share_attn/test/test_20 : 8340\n",
      "cnn_share_attn/test/test_im_140 : 0\n",
      "cnn_share_attn/test/test_140 : 8340\n",
      "cnn_split_attn/val/test_0 : 4169\n",
      "cnn_split_attn/val/test_im_60 : 0\n",
      "cnn_split_attn/val/test_im_100 : 0\n",
      "cnn_split_attn/val/test_40 : 4169\n",
      "cnn_split_attn/val/test_120 : 4169\n",
      "cnn_split_attn/val/test_im_10 : 0\n",
      "cnn_split_attn/val/test_140 : 4169\n",
      "cnn_split_attn/val/test_im_80 : 0\n",
      "cnn_split_attn/val/test_20 : 4169\n",
      "cnn_split_attn/val/test_10 : 4169\n",
      "cnn_split_attn/val/test_100 : 4169\n",
      "cnn_split_attn/val/test_im_0 : 0\n",
      "cnn_split_attn/val/test_im_120 : 0\n",
      "cnn_split_attn/val/test_60 : 4169\n",
      "cnn_split_attn/val/test_im_40 : 0\n",
      "cnn_split_attn/val/test_80 : 4169\n",
      "cnn_split_attn/val/test_im_20 : 0\n",
      "cnn_split_attn/val/test_im_140 : 0\n",
      "cnn_split_attn/test/test_10 : 8340\n",
      "cnn_split_attn/test/test_im_20 : 0\n",
      "cnn_split_attn/test/test_60 : 8340\n",
      "cnn_split_attn/test/test_im_120 : 0\n",
      "cnn_split_attn/test/test_140 : 8340\n",
      "cnn_split_attn/test/test_120 : 8340\n",
      "cnn_split_attn/test/test_80 : 8340\n",
      "cnn_split_attn/test/test_im_140 : 0\n",
      "cnn_split_attn/test/test_0 : 8340\n",
      "cnn_split_attn/test/test_im_40 : 0\n",
      "cnn_split_attn/test/test_40 : 8340\n",
      "cnn_split_attn/test/test_im_100 : 0\n",
      "cnn_split_attn/test/test_im_80 : 0\n",
      "cnn_split_attn/test/test_im_0 : 0\n",
      "cnn_split_attn/test/test_im_60 : 0\n",
      "cnn_split_attn/test/test_im_10 : 0\n",
      "cnn_split_attn/test/test_20 : 8340\n",
      "cnn_split_attn/test/test_100 : 8340\n",
      "cnn/val/test_im_80 : 0\n",
      "cnn/val/test_im_140 : 0\n",
      "cnn/val/test_120 : 4169\n",
      "cnn/val/test_40 : 4169\n",
      "cnn/val/test_im_10 : 0\n",
      "cnn/val/test_20 : 4169\n",
      "cnn/val/test_im_120 : 0\n",
      "cnn/val/test_140 : 4169\n",
      "cnn/val/test_im_60 : 0\n",
      "cnn/val/test_im_200 : 0\n",
      "cnn/val/test_60 : 4169\n",
      "cnn/val/test_im_0 : 0\n",
      "cnn/val/test_0 : 4169\n",
      "cnn/val/test_180 : 4169\n",
      "cnn/val/test_10 : 4169\n",
      "cnn/val/test_im_160 : 0\n",
      "cnn/val/test_im_20 : 0\n",
      "cnn/val/test_100 : 4169\n",
      "cnn/val/test_im_180 : 0\n",
      "cnn/val/test_im_100 : 0\n",
      "cnn/val/test_im_40 : 0\n",
      "cnn/val/test_160 : 4169\n",
      "cnn/val/test_80 : 4169\n",
      "cnn/val/test_200 : 4169\n",
      "cnn/test/test_10 : 8340\n",
      "cnn/test/test_im_100 : 0\n",
      "cnn/test/test_im_0 : 0\n",
      "cnn/test/test_im_180 : 0\n",
      "cnn/test/test_140 : 8340\n",
      "cnn/test/test_im_40 : 0\n",
      "cnn/test/test_0 : 8340\n",
      "cnn/test/test_60 : 8340\n",
      "cnn/test/test_80 : 8340\n",
      "cnn/test/test_im_20 : 0\n",
      "cnn/test/test_im_200 : 0\n",
      "cnn/test/test_im_160 : 0\n",
      "cnn/test/test_120 : 8340\n",
      "cnn/test/test_im_60 : 0\n",
      "cnn/test/test_40 : 8340\n",
      "cnn/test/test_200 : 8340\n",
      "cnn/test/test_im_120 : 0\n",
      "cnn/test/test_im_10 : 0\n",
      "cnn/test/test_160 : 8340\n",
      "cnn/test/test_im_140 : 0\n",
      "cnn/test/test_180 : 8340\n",
      "cnn/test/test_100 : 8340\n",
      "cnn/test/test_im_80 : 0\n",
      "cnn/test/test_20 : 8340\n"
     ]
    }
   ],
   "source": [
    "for m in all_data.keys():\n",
    "    for s in all_data[m].keys():\n",
    "        for dir in os.listdir(os.path.join(\"latent_code\", m, s)):\n",
    "            count = sum([len(list(os.listdir(os.path.join(\"latent_code\", m, s, dir, i)))) for i in os.listdir(os.path.join(\"latent_code\", m, s, dir))])\n",
    "            print(f\"{os.path.join(m, s, dir)} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_data = {}\n",
    "# for idx in range(num_test):\n",
    "#     kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "#     acc = []\n",
    "#     total_mis = 0\n",
    "#     clusters = []\n",
    "#     new_cluster, cluster_map = map_label(kmeans.labels_, labels[idx])\n",
    "#     # cluster_map = {classes[old] : new for old, new in cluster_map.items()}\n",
    "#     # print(cluster_map)\n",
    "#     for i in range(len(classes)):\n",
    "#         mask = (labels[idx] == i)\n",
    "#         cluster = new_cluster[mask]\n",
    "#         cur_acc = (cluster == i).mean()\n",
    "#         acc.append(f\"{cur_acc: .2f}\")\n",
    "#         clusters.append(cluster)\n",
    "#         # if classes[i] == \"Violin_Mode\" or i == 0:\n",
    "#         #     print(kmeans.labels_[mask])\n",
    "\n",
    "#     cluster_class = classes\n",
    "#     # cluster_class = [\"\"] * len(classes)\n",
    "#     # for k,v in cluster_map.items():\n",
    "#     #     cluster_class[v] += f\"/{k}\"\n",
    "\n",
    "#     # for i in range(len(cluster_class)):\n",
    "#     #     if cluster_class[i] == \"\":\n",
    "#     #         cluster_class[i] = \"None\"\n",
    "\n",
    "\n",
    "#     show_data[f\"mAP_{20 * idx + 20}\"] = acc + [(new_cluster == labels[idx]).mean()]\n",
    "\n",
    "#     # print(cluster_map)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# mis_class = 0\n",
    "# mask = (labels == class_idx)\n",
    "# fname = np.array(fnames)[mask][clusters[class_idx] == mis_class]\n",
    "# print(fname.shape)\n",
    "# random.shuffle(fname)\n",
    "# data = [np.array(Image.open(fname[i][:-4].replace(\"test\", \"test_im\"))) for i in range(4)]\n",
    "# data = np.vstack(data)\n",
    "# fig = plt.figure(figsize=(30, 30)) \n",
    "# fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(data)\n",
    "# plt.title(f\"{class_idx}-{mis_class}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class_idx = 0\n",
    "# mis_class = 21\n",
    "# mask = (labels == class_idx)\n",
    "# fname = np.array(fnames)[mask][clusters[class_idx] == mis_class]\n",
    "# print(fname.shape)\n",
    "# random.shuffle(fname)\n",
    "\n",
    "# data = [np.array(Image.open(fname[i][:-4].replace(\"test\", \"test_im\"))) for i in range(4)]\n",
    "# data = np.vstack(data)\n",
    "# fig.add_subplot(1, 2, 2)\n",
    "# plt.imshow(data)\n",
    "# plt.title(f\"{class_idx}-{mis_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, cluster in enumerate(clusters):\n",
    "#     fig, ax = plt.subplots(figsize=(20, 10))\n",
    "#     counts, bins, patches = ax.hist(cluster, list(range(len(classes))))\n",
    "#     ax.set_title(classes[i])\n",
    "#     ax.set_xlabel(\"Cluster\")\n",
    "#     ax.set_ylabel(\"Number\")\n",
    "#     ax.set_xticks(bins + 0.5)\n",
    "#     ax.set_xticklabels(classes, rotation=60, ha=\"right\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m----> 2\u001b[0m x_embedded \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1110\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# TSNE.metric is not validated yet\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:820\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "x_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib._color_data as mcd\n",
    "palette = list(mcd.XKCD_COLORS.values())[::10]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:500, :]\n",
    "    plt.figure()\n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i])\n",
    "    plt.title(classes[i])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:50, :]\n",
    "    \n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:50, :].mean(0, keepdims=True)\n",
    "    \n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i], label=classes[i])\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:500, :]\n",
    "    # Configure the trace.\n",
    "    trace = go.Scatter3d(\n",
    "        x=x_show[:, 0],  \n",
    "        y=x_show[:, 1], \n",
    "        z=x_show[:, 2], \n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'opacity': 0.8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=Scene(\n",
    "                xaxis=XAxis(title=classes[i]),\n",
    "                yaxis=YAxis(title=classes[i]),\n",
    "                zaxis=ZAxis(title=classes[i])\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    # Render the plot.\n",
    "    plotly.offline.iplot(plot_figure)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:100, :]\n",
    "    cluster = kmeans.labels_[mask]\n",
    "    # mask = cluster == 14\n",
    "    # x_show = x_show[mask]\n",
    "    # Configure the trace.\n",
    "    trace = go.Scatter3d(\n",
    "        x=x_show[:, 0],  \n",
    "        y=x_show[:, 1], \n",
    "        z=x_show[:, 2], \n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'opacity': 0.8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=Scene(\n",
    "                xaxis=XAxis(title=classes[i]),\n",
    "                yaxis=YAxis(title=classes[i]),\n",
    "                zaxis=ZAxis(title=classes[i])\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data.append(trace)\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Render the plot.\n",
    "plotly.offline.iplot(plot_figure)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggin_face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
