{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, rand_score\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from munkres import Munkres\n",
    "from scipy.special import comb\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "\n",
    "\n",
    "def map_label(pred, gt):\n",
    "    \"\"\"entry point\"\"\"\n",
    "\n",
    "    num_labels = len(np.unique(gt))\n",
    "\n",
    "    # cm = confusion_matrix(gt, pred, labels=range(num_labels)) # gets the confusion matrix\n",
    "\n",
    "    cost_matrix = make_cost_matrix(pred, gt)\n",
    "\n",
    "    m = Munkres()\n",
    "    indexes = m.compute(cost_matrix)\n",
    "    mapper = { old: new for (old, new) in indexes }\n",
    "\n",
    "\n",
    "    new_labels = translate_clustering(pred, mapper)\n",
    "    new_cm = confusion_matrix(gt, new_labels, labels=range(num_labels))\n",
    "    return new_labels, mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_vote(nn_class, labels, k):\n",
    "    cur = 0\n",
    "    for i in range(nn_class.shape[0]):\n",
    "        max_num = 0\n",
    "        for j in range(k):\n",
    "            if ((nn_class[i, :] == nn_class[i, j]).sum() > max_num) or \\\n",
    "            (k > 1 and (nn_class[i, :] == nn_class[i, j]).sum() == max_num and nn_class[i, j] != labels[i]):\n",
    "                max_num = (nn_class[i, :] == nn_class[i, j]).sum()\n",
    "                max_class = nn_class[i, j]\n",
    "        \n",
    "        if max_class == labels[i]:\n",
    "            cur += 1\n",
    "    return cur\n",
    "\n",
    "\n",
    "def mean_average_precision(index, label):\n",
    "    correct = (index == label[:, None]).astype(np.int32)\n",
    "    precision = np.cumsum(correct, 1) / (np.arange(index.shape[1])[None, :] + 1)\n",
    "    res = (precision * correct).sum(1) / (correct.sum(1) + 1e-6)\n",
    "    return res.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_code/vit_share/val\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_code/vit_share/test\n",
      "\n",
      "latent_code/cnn_share_attn/val\n",
      "\n",
      "latent_code/cnn_share_attn/test\n",
      "\n",
      "latent_code/cnn_split_attn/val\n",
      "\n",
      "latent_code/cnn_split_attn/test\n",
      "\n",
      "latent_code/cnn/val\n",
      "\n",
      "latent_code/cnn/test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "for model_dir in os.listdir(\"latent_code\"):\n",
    "    all_data[model_dir] = {}\n",
    "    for s in [\"val\", \"test\"]:\n",
    "        test_dir = os.path.join(\"latent_code\", model_dir, s)\n",
    "\n",
    "        num_test = len(os.listdir(test_dir)) // 2\n",
    "\n",
    "        classes = [dir for dir in os.listdir(f\"{test_dir}/test_0\")]\n",
    "        classes.sort()\n",
    "        print(test_dir)\n",
    "        print()\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "        fnames = []\n",
    "\n",
    "        idx_num = [int(fname.split(\"_\")[-1]) for fname in os.listdir(f\"{test_dir}\") if \"im\" not in fname]\n",
    "        idx_num.sort()\n",
    "        num_file = 0\n",
    "        for i, dir in enumerate(classes):\n",
    "            _dir = os.path.join(f\"{test_dir}/test_0\")\n",
    "            for fname in os.listdir(os.path.join(_dir, dir)):\n",
    "                num_file += 1\n",
    "\n",
    "\n",
    "        shuffle_idx = np.arange(num_file)\n",
    "        np.random.shuffle(shuffle_idx)\n",
    "\n",
    "\n",
    "\n",
    "        for idx in idx_num:\n",
    "            data_tmp = []\n",
    "            label_tmp = []\n",
    "            fnames_tmp = []\n",
    "            for i, dir in enumerate(classes):\n",
    "                _dir = os.path.join(f\"{test_dir}/test_{idx}\")\n",
    "                for fname in os.listdir(os.path.join(_dir, dir)):\n",
    "                    data_tmp.append(np.load(os.path.join(_dir, dir, fname)))\n",
    "                    label_tmp.append(i)\n",
    "                    fnames_tmp.append(os.path.join(_dir, dir, fname))\n",
    "\n",
    "            data.append(np.vstack(data_tmp)[shuffle_idx, :])\n",
    "            labels.append(np.array(label_tmp)[shuffle_idx])\n",
    "            fnames.append(np.array(fnames_tmp)[shuffle_idx])\n",
    "        all_data[model_dir][s] = dict(data=data, labels=labels, fnames=fnames, idx_num=idx_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.491005 │ 0.78604  │ 0.734709 │ 0.711681 │ 0.69729  │ 0.694891 │ 0.692492 │ 0.686735 │ 0.682898 │ 0.683377 │ 0.684817 │ 0.681938 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.465339 │ 0.782202 │ 0.728952 │ 0.693692 │ 0.686256 │ 0.688414 │ 0.682898 │ 0.6793   │ 0.677621 │ 0.675222 │ 0.679779 │ 0.674502 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.49988  │ 0.783881 │ 0.73207  │ 0.693452 │ 0.688175 │ 0.687695 │ 0.684817 │ 0.686496 │ 0.679539 │ 0.681219 │ 0.684817 │ 0.67906  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.505877 │ 0.78628  │ 0.733989 │ 0.700648 │ 0.69633  │ 0.688894 │ 0.683137 │ 0.693692 │ 0.691533 │ 0.685536 │ 0.691533 │ 0.684337 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.519309 │ 0.776925 │ 0.722236 │ 0.69681  │ 0.684577 │ 0.680739 │ 0.677381 │ 0.682418 │ 0.682178 │ 0.680019 │ 0.681458 │ 0.674502 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.505036 │ 0.788849 │ 0.747842 │ 0.726259 │ 0.711151 │ 0.707914 │ 0.708153 │ 0.705156 │ 0.703597 │ 0.699281 │ 0.703597 │ 0.705156 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.480096 │ 0.792926 │ 0.740767 │ 0.71211  │ 0.704556 │ 0.699161 │ 0.703957 │ 0.701799 │ 0.697122 │ 0.696523 │ 0.7      │ 0.697002 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.501199 │ 0.796882 │ 0.745444 │ 0.714508 │ 0.706235 │ 0.702638 │ 0.705516 │ 0.705036 │ 0.702398 │ 0.698321 │ 0.704197 │ 0.702038 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.51211  │ 0.797002 │ 0.74964  │ 0.726619 │ 0.717266 │ 0.71235  │ 0.709712 │ 0.715348 │ 0.707314 │ 0.702158 │ 0.708393 │ 0.710312 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.527938 │ 0.793405 │ 0.744005 │ 0.720504 │ 0.705755 │ 0.703597 │ 0.70036  │ 0.703477 │ 0.696882 │ 0.694365 │ 0.699281 │ 0.701079 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.349964 │ 0.722955 │ 0.769729 │ 0.760614 │ 0.727273 │ 0.720796 │ 0.712401 │ 0.723675 │ 0.71408  │ 0.71504  │ 0.719117 │ 0.71408  │ 0.717438 │ 0.720317 │ 0.723195 │ 0.719837 │ 0.721756 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.279923 │ 0.720556 │ 0.762053 │ 0.754378 │ 0.712641 │ 0.707604 │ 0.707844 │ 0.710002 │ 0.705685 │ 0.706404 │ 0.712641 │ 0.709763 │ 0.711202 │ 0.717678 │ 0.709523 │ 0.7136   │ 0.710962 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.342048 │ 0.727273 │ 0.769489 │ 0.755817 │ 0.718158 │ 0.712161 │ 0.701607 │ 0.713361 │ 0.702327 │ 0.702806 │ 0.716959 │ 0.71456  │ 0.713121 │ 0.721036 │ 0.7148   │ 0.711202 │ 0.71456  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.345646 │ 0.730871 │ 0.772367 │ 0.761094 │ 0.718877 │ 0.710482 │ 0.703766 │ 0.720556 │ 0.706884 │ 0.712401 │ 0.719837 │ 0.717918 │ 0.715759 │ 0.721036 │ 0.719597 │ 0.722715 │ 0.718158 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.372511 │ 0.727513 │ 0.761574 │ 0.744303 │ 0.712641 │ 0.700168 │ 0.69609  │ 0.702806 │ 0.69705  │ 0.69705  │ 0.708563 │ 0.709763 │ 0.710242 │ 0.711681 │ 0.712161 │ 0.710722 │ 0.708803 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.341607 │ 0.73717  │ 0.780216 │ 0.764269 │ 0.727818 │ 0.728058 │ 0.722662 │ 0.735012 │ 0.721823 │ 0.720144 │ 0.735252 │ 0.723141 │ 0.729976 │ 0.731894 │ 0.730216 │ 0.733213 │ 0.731775 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.276619 │ 0.741607 │ 0.781535 │ 0.76295  │ 0.733933 │ 0.726379 │ 0.721942 │ 0.731055 │ 0.723141 │ 0.721223 │ 0.734293 │ 0.72458  │ 0.727338 │ 0.727578 │ 0.727458 │ 0.734053 │ 0.731535 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.338249 │ 0.741607 │ 0.788489 │ 0.772182 │ 0.738969 │ 0.730935 │ 0.729257 │ 0.734532 │ 0.722422 │ 0.723501 │ 0.73789  │ 0.7253   │ 0.732494 │ 0.73693  │ 0.733213 │ 0.736451 │ 0.735851 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.353837 │ 0.748201 │ 0.792206 │ 0.77446  │ 0.747362 │ 0.73801  │ 0.736091 │ 0.745444 │ 0.734772 │ 0.73801  │ 0.745803 │ 0.732494 │ 0.738249 │ 0.740288 │ 0.741247 │ 0.746643 │ 0.740647 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.379257 │ 0.742806 │ 0.786571 │ 0.763189 │ 0.739688 │ 0.729376 │ 0.727218 │ 0.73753  │ 0.724221 │ 0.72494  │ 0.730096 │ 0.726499 │ 0.729736 │ 0.732374 │ 0.730336 │ 0.732134 │ 0.733333 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.333893 │ 0.753898 │ 0.735428 │ 0.715279 │ 0.703046 │ 0.701607 │ 0.699448 │ 0.699688 │ 0.690813 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.271768 │ 0.754378 │ 0.720556 │ 0.691773 │ 0.69561  │ 0.693212 │ 0.698009 │ 0.69561  │ 0.695371 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.328376 │ 0.753418 │ 0.718398 │ 0.692252 │ 0.693212 │ 0.695371 │ 0.694411 │ 0.69657  │ 0.700648 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.337491 │ 0.757976 │ 0.720317 │ 0.706165 │ 0.700168 │ 0.702327 │ 0.705685 │ 0.704725 │ 0.707604 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.361717 │ 0.754857 │ 0.712401 │ 0.69681  │ 0.693931 │ 0.690094 │ 0.692012 │ 0.69561  │ 0.692732 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.347962 │ 0.769305 │ 0.739448 │ 0.722422 │ 0.724221 │ 0.722182 │ 0.719784 │ 0.722182 │ 0.723861 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.278537 │ 0.768945 │ 0.738249 │ 0.719065 │ 0.713669 │ 0.71247  │ 0.713309 │ 0.709592 │ 0.711151 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.330096 │ 0.776139 │ 0.739808 │ 0.718705 │ 0.716427 │ 0.716187 │ 0.71271  │ 0.715588 │ 0.714508 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.341966 │ 0.780336 │ 0.747962 │ 0.733813 │ 0.726859 │ 0.723741 │ 0.718945 │ 0.721942 │ 0.72542  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.367626 │ 0.77506  │ 0.743885 │ 0.720863 │ 0.716427 │ 0.710911 │ 0.711751 │ 0.713429 │ 0.711511 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================vit_share-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.614776 │ 0.451427 │ 0.591269 │ 0.441833 │ 0.402495 │ 0.509715 │ 0.361717 │ 0.295035 │ 0.344447 │ 0.305109 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.583833 │ 0.400816 │ 0.562725 │ 0.383065 │ 0.330535 │ 0.453826 │ 0.294795 │ 0.218997 │ 0.272727 │ 0.224035 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.596306 │ 0.433437 │ 0.566323 │ 0.424562 │ 0.377549 │ 0.472775 │ 0.337011 │ 0.275366 │ 0.3219   │ 0.277045 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.601343 │ 0.447349 │ 0.57112  │ 0.443751 │ 0.391701 │ 0.479971 │ 0.340609 │ 0.280403 │ 0.323339 │ 0.283041 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.602782 │ 0.466539 │ 0.563205 │ 0.455025 │ 0.41017  │ 0.491005 │ 0.355721 │ 0.297194 │ 0.33989  │ 0.295994 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================vit_share-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.635731 │ 0.479017 │ 0.598441 │ 0.436451 │ 0.42458  │ 0.520863 │ 0.385851 │ 0.315947 │ 0.360671 │ 0.309952 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.610791 │ 0.431415 │ 0.5747   │ 0.389448 │ 0.366187 │ 0.484652 │ 0.31271  │ 0.238489 │ 0.291727 │ 0.241966 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.623981 │ 0.464868 │ 0.586211 │ 0.434293 │ 0.410791 │ 0.508873 │ 0.358633 │ 0.294245 │ 0.339568 │ 0.28705  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.631415 │ 0.476978 │ 0.595923 │ 0.448561 │ 0.416427 │ 0.519185 │ 0.367506 │ 0.302878 │ 0.347482 │ 0.298561 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.629257 │ 0.48777  │ 0.601799 │ 0.467986 │ 0.430216 │ 0.52458  │ 0.378657 │ 0.323621 │ 0.359592 │ 0.309233 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(all_data.keys()):\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "\n",
    "            # for k in ks:\n",
    "\n",
    "            #     index = indices[:, :k]\n",
    "            #     nn_class = labels[idx][index]\n",
    "            #     acc = []\n",
    "                \n",
    "            #     for c in range(len(classes)):\n",
    "            #         cur = 0\n",
    "            #         mask = (labels[idx] == c)\n",
    "            #         nn_class_msk = nn_class[mask]\n",
    "            #         cur = most_vote(nn_class_msk, labels[idx][mask], k)\n",
    "                    \n",
    "            #         acc.append(cur / nn_class_msk.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #     total_acc = most_vote(nn_class, labels[idx], k) / nn_class.shape[0]\n",
    "\n",
    "\n",
    "            #     # show_data[f\"Top{k}_{num}\"] =  acc + [total_acc] \n",
    "            #     show_data[f\"Top{k}_{num}\"] =  [total_acc] \n",
    "\n",
    "\n",
    "\n",
    "            acc = []\n",
    "            for k in ks:\n",
    "\n",
    "                index = indices[:, :k]\n",
    "                nn_class = labels[idx][index]\n",
    "                \n",
    "            \n",
    "                total_acc = most_vote(nn_class, labels[idx], k) / nn_class.shape[0]\n",
    "                acc.append(total_acc)\n",
    "\n",
    "            show_data[f\"{num}\"] =  acc\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "        # df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "        df = pd.DataFrame(data=show_data, index=[f\"Top{k}\" for k in ks])\n",
    "        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.562286 │ 0.806557 │ 0.763926 │ 0.737759 │ 0.727211 │ 0.724302 │  0.724665 │  0.722477 │  0.720352 │  0.717085 │  0.719464 │  0.718865 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.572765 │ 0.815378 │ 0.774873 │ 0.750443 │ 0.741364 │ 0.738706 │  0.739291 │  0.739238 │  0.736196 │  0.734198 │  0.736799 │   0.73615 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_share_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │   mAP_220 │   mAP_240 │   mAP_260 │   mAP_280 │   mAP_300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.438644 │ 0.758745 │ 0.794347 │ 0.785209 │ 0.750883 │ 0.749034 │  0.742541 │   0.75038 │   0.74029 │  0.739723 │  0.746478 │  0.741855 │  0.743439 │   0.74582 │  0.745097 │  0.746352 │  0.745508 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_share_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │   mAP_220 │   mAP_240 │   mAP_260 │   mAP_280 │   mAP_300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.442732 │ 0.773245 │ 0.807204 │ 0.794759 │ 0.765211 │ 0.760808 │  0.756254 │  0.763001 │  0.752644 │  0.753162 │  0.761451 │  0.754167 │  0.758547 │  0.759436 │  0.758729 │  0.762895 │  0.760188 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_split_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.427438 │ 0.784775 │ 0.760907 │ 0.742011 │ 0.737158 │ 0.735218 │  0.734769 │  0.734084 │  0.730952 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_split_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.440743 │ 0.797459 │ 0.772386 │ 0.753872 │ 0.750678 │ 0.747252 │  0.746626 │  0.747226 │  0.747398 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================vit_share-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.658037 │ 0.522834 │ 0.629474 │ 0.514213 │ 0.480163 │  0.564425 │  0.447034 │  0.393754 │  0.433115 │  0.399068 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================vit_share-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.680182 │ 0.542689 │ 0.642244 │ 0.519187 │ 0.502804 │  0.582416 │  0.467173 │  0.408477 │   0.44303 │  0.407648 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for m in sorted(all_data.keys()):\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            \n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "\n",
    "            nn_class = labels[idx][indices]\n",
    "            acc = []\n",
    "            \n",
    "            for c in range(len(classes)):\n",
    "                mask = (labels[idx] == c)\n",
    "                nn_class_msk = nn_class[mask]\n",
    "                cur = mean_average_precision(nn_class_msk, labels[idx][mask])\n",
    "                acc.append(cur)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            total_acc = mean_average_precision(nn_class, labels[idx])\n",
    "\n",
    "\n",
    "            # show_data[f\"mAP_{num}\"] =  acc + [total_acc] \n",
    "            show_data[f\"mAP_{num}\"] =  [total_acc] \n",
    "                \n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "\n",
    "        # df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "        df = pd.DataFrame(data=show_data, index=[\"total\"])\n",
    "        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.427235 │ 0.46242  │ 0.437293 │ 0.399308 │ 0.395758 │ 0.394423 │ 0.379391 │ 0.415837 │ 0.371071 │ 0.375071 │ 0.392801 │ 0.372735 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.175332 │ 0.283177 │ 0.321714 │ 0.30117  │ 0.304862 │ 0.39166  │ 0.343985 │ 0.33215  │ 0.412642 │ 0.354816 │ 0.349503 │ 0.30704  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.843011 │ 0.896153 │ 0.909738 │ 0.907151 │ 0.908403 │ 0.925938 │ 0.918282 │ 0.913653 │ 0.929652 │ 0.920544 │ 0.918638 │ 0.910722 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.177742 │ 0.298341 │ 0.323298 │ 0.294462 │ 0.296065 │ 0.3536   │ 0.317284 │ 0.323588 │ 0.353536 │ 0.322319 │ 0.326559 │ 0.289332 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.430217 │ 0.569181 │ 0.568068 │ 0.56271  │ 0.565096 │ 0.593965 │ 0.57859  │ 0.580424 │ 0.599622 │ 0.586937 │ 0.57674  │ 0.573613 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.421329 │ 0.447095 │ 0.412451 │ 0.382133 │ 0.383052 │ 0.379203 │ 0.364942 │ 0.360386 │ 0.379961 │ 0.354168 │ 0.359636 │ 0.365145 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.161613 │ 0.303047 │ 0.325689 │ 0.317771 │ 0.317793 │ 0.352077 │ 0.351935 │ 0.352496 │ 0.397675 │ 0.349763 │ 0.343075 │ 0.331372 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.831654 │ 0.903711 │ 0.912215 │ 0.912411 │ 0.912352 │ 0.919697 │ 0.920401 │ 0.920734 │ 0.927194 │ 0.920573 │ 0.919066 │ 0.91647  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.159638 │ 0.311242 │ 0.317524 │ 0.300475 │ 0.300842 │ 0.322338 │ 0.315904 │ 0.314169 │ 0.34993  │ 0.309647 │ 0.308027 │ 0.302931 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.420591 │ 0.583241 │ 0.566106 │ 0.565018 │ 0.568006 │ 0.578953 │ 0.578366 │ 0.567991 │ 0.577093 │ 0.559663 │ 0.569574 │ 0.572731 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.31794  │ 0.512185 │ 0.495027 │ 0.426521 │ 0.479497 │ 0.422753 │ 0.430232 │ 0.42026  │ 0.451462 │ 0.444669 │ 0.455839 │ 0.516715 │ 0.424915 │ 0.407717 │ 0.417062 │ 0.440864 │ 0.423172 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.180297 │ 0.214033 │ 0.321766 │ 0.352602 │ 0.337068 │ 0.361171 │ 0.408778 │ 0.402485 │ 0.414116 │ 0.407284 │ 0.414588 │ 0.42599  │ 0.369962 │ 0.418022 │ 0.440866 │ 0.412014 │ 0.403057 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.870655 │ 0.855996 │ 0.905863 │ 0.917525 │ 0.911022 │ 0.919446 │ 0.927531 │ 0.926824 │ 0.92782  │ 0.926896 │ 0.927786 │ 0.928289 │ 0.921044 │ 0.929482 │ 0.932402 │ 0.927757 │ 0.926829 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.165344 │ 0.236424 │ 0.341494 │ 0.342275 │ 0.349408 │ 0.346706 │ 0.380612 │ 0.372188 │ 0.393522 │ 0.386202 │ 0.39576  │ 0.428927 │ 0.353518 │ 0.3753   │ 0.392739 │ 0.387451 │ 0.373877 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.386781 │ 0.522487 │ 0.604782 │ 0.59527  │ 0.608281 │ 0.599453 │ 0.616063 │ 0.613406 │ 0.633561 │ 0.622951 │ 0.621942 │ 0.633692 │ 0.602187 │ 0.620754 │ 0.616239 │ 0.614248 │ 0.609068 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.223099 │ 0.508678 │ 0.462743 │ 0.424945 │ 0.47278  │ 0.389828 │ 0.445741 │ 0.408723 │ 0.428792 │ 0.392959 │ 0.44757  │ 0.432035 │ 0.416549 │ 0.419173 │ 0.414179 │ 0.416336 │ 0.404923 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.204768 │ 0.201448 │ 0.305099 │ 0.357989 │ 0.339338 │ 0.362556 │ 0.351942 │ 0.445921 │ 0.405846 │ 0.418882 │ 0.422161 │ 0.390643 │ 0.376262 │ 0.400011 │ 0.397679 │ 0.409423 │ 0.398102 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.899924 │ 0.847282 │ 0.903098 │ 0.91857  │ 0.911839 │ 0.921102 │ 0.916262 │ 0.933064 │ 0.926986 │ 0.929833 │ 0.92905  │ 0.924371 │ 0.922417 │ 0.92634  │ 0.926122 │ 0.927883 │ 0.926478 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.160208 │ 0.220604 │ 0.317653 │ 0.345326 │ 0.348932 │ 0.333647 │ 0.349021 │ 0.391042 │ 0.378089 │ 0.368263 │ 0.39668  │ 0.370001 │ 0.354045 │ 0.370112 │ 0.366391 │ 0.374435 │ 0.36232  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.367358 │ 0.509878 │ 0.580506 │ 0.591208 │ 0.602978 │ 0.584931 │ 0.59844  │ 0.621485 │ 0.618586 │ 0.61492  │ 0.622119 │ 0.605823 │ 0.599904 │ 0.601478 │ 0.603102 │ 0.606923 │ 0.611401 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.278453 │ 0.517868 │ 0.392986 │ 0.389374 │ 0.410264 │ 0.38388  │ 0.408651 │ 0.403429 │ 0.404173 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.159278 │ 0.213855 │ 0.340955 │ 0.345678 │ 0.355318 │ 0.329011 │ 0.332215 │ 0.328368 │ 0.383554 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.866778 │ 0.854951 │ 0.916915 │ 0.918068 │ 0.918892 │ 0.914946 │ 0.914109 │ 0.913565 │ 0.924285 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.135799 │ 0.237051 │ 0.320914 │ 0.322596 │ 0.337662 │ 0.309097 │ 0.320948 │ 0.316214 │ 0.353245 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.349716 │ 0.538402 │ 0.583624 │ 0.583796 │ 0.594615 │ 0.575823 │ 0.579977 │ 0.57255  │ 0.601595 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.25922  │ 0.536645 │ 0.391552 │ 0.384187 │ 0.380697 │ 0.387468 │ 0.41022  │ 0.378678 │ 0.387012 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.17088  │ 0.196914 │ 0.318246 │ 0.318792 │ 0.329366 │ 0.307294 │ 0.358998 │ 0.32189  │ 0.383547 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.878293 │ 0.838498 │ 0.911865 │ 0.912504 │ 0.91508  │ 0.909507 │ 0.919478 │ 0.913581 │ 0.92479  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.143074 │ 0.218475 │ 0.304376 │ 0.301986 │ 0.307987 │ 0.294858 │ 0.340036 │ 0.302031 │ 0.345217 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.354375 │ 0.522692 │ 0.560335 │ 0.565599 │ 0.572626 │ 0.567646 │ 0.596816 │ 0.572656 │ 0.598453 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================vit_share-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│             │        0 │       20 │       40 │       60 │        80 │      100 │       120 │       140 │       160 │       180 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ precision   │ 0.399934 │ 0.200273 │ 0.263364 │ 0.204345 │ 0.177731  │ 0.209088 │ 0.132954  │ 0.136604  │ 0.143055  │ 0.1226    │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ recall      │ 0.12247  │ 0.174836 │ 0.208206 │ 0.167362 │ 0.131393  │ 0.140747 │ 0.1073    │ 0.107882  │ 0.107029  │ 0.106971  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ accuracy    │ 0.789301 │ 0.893915 │ 0.894326 │ 0.889821 │ 0.878579  │ 0.874312 │ 0.880039  │ 0.878833  │ 0.875339  │ 0.884433  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ adjusted RI │ 0.104124 │ 0.130228 │ 0.176648 │ 0.125563 │ 0.0872821 │ 0.10306  │ 0.0551833 │ 0.0564536 │ 0.0568475 │ 0.0527438 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼──────────┼───────────┼───────────┼───────────┼───────────┤\n",
      "│ nmi         │ 0.330341 │ 0.329847 │ 0.408318 │ 0.306251 │ 0.255822  │ 0.289638 │ 0.204824  │ 0.200265  │ 0.203008  │ 0.185081  │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================vit_share-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤══════════╤═══════════╕\n",
      "│             │        0 │       20 │       40 │       60 │        80 │       100 │       120 │       140 │      160 │       180 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪══════════╪═══════════╡\n",
      "│ precision   │ 0.408368 │ 0.213762 │ 0.322494 │ 0.181917 │ 0.160203  │ 0.173924  │ 0.132976  │ 0.125743  │ 0.135353 │ 0.115665  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┤\n",
      "│ recall      │ 0.130121 │ 0.176742 │ 0.194758 │ 0.173175 │ 0.129857  │ 0.139953  │ 0.101872  │ 0.111139  │ 0.107106 │ 0.104752  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┤\n",
      "│ accuracy    │ 0.797719 │ 0.891483 │ 0.877541 │ 0.897286 │ 0.883484  │ 0.884605  │ 0.875805  │ 0.885516  │ 0.878628 │ 0.885946  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┤\n",
      "│ adjusted RI │ 0.115676 │ 0.135885 │ 0.180633 │ 0.122697 │ 0.0816664 │ 0.0939516 │ 0.0498371 │ 0.0570252 │ 0.055355 │ 0.0491671 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼───────────┼───────────┼───────────┼───────────┼──────────┼───────────┤\n",
      "│ nmi         │ 0.368218 │ 0.339753 │ 0.397829 │ 0.313157 │ 0.253211  │ 0.276411  │ 0.186486  │ 0.195822  │ 0.196252 │ 0.176558  │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧══════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "def confusion(actual, pred):\n",
    "\n",
    "    tp_plus_fp = comb(np.bincount(actual), 2).sum()\n",
    "    tp_plus_fn = comb(np.bincount(pred), 2).sum()\n",
    "    A = np.c_[(actual, pred)]\n",
    "    tp = sum(comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum()\n",
    "             for i in set(actual))\n",
    "    fp = tp_plus_fp - tp\n",
    "    fn = tp_plus_fn - tp\n",
    "    tn = comb(len(A), 2) - tp - fp - fn\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "for m in sorted(all_data.keys()):\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "            tp, tn, fp, fn = confusion(labels[idx], kmeans.labels_)\n",
    "            total_prec = tp / (tp + fp)\n",
    "            total_rec = tp / (tp + fn)\n",
    "            total_acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "            total_ari = adjusted_rand_score(labels[idx], kmeans.labels_)\n",
    "            total_nmi = normalized_mutual_info_score(labels[idx], kmeans.labels_)\n",
    "\n",
    "            show_data[f\"{num}\"] = [f\"{total_prec}\", f\"{total_rec}\", f\"{total_acc}\", f\"{total_ari}\", f\"{total_nmi}\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "        df = pd.DataFrame(data=show_data, index=[\"precision\", \"recall\", \"accuracy\", \"adjusted RI\", \"nmi\"])\n",
    "        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═══════════╤══════════════════════╤══════════════════════╤═════════════════╕\n",
      "│           │   cnn-val │   cnn_share_attn-val │   cnn_split_attn-val │   vit_share-val │\n",
      "╞═══════════╪═══════════╪══════════════════════╪══════════════════════╪═════════════════╡\n",
      "│ Top_1     │  0.734709 │             0.71408  │             0.690813 │        0.591269 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ Top_3     │  0.733509 │             0.720796 │             0.708083 │        0.581434 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ Top_5     │  0.723675 │             0.709763 │             0.694891 │        0.565603 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ Top_7     │  0.722236 │             0.709763 │             0.692732 │        0.563205 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ Top_10    │  0.722236 │             0.709763 │             0.692732 │        0.563205 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ mean_ap   │  0.763926 │             0.741855 │             0.730952 │        0.629474 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ total_ari │  0.323298 │             0.428927 │             0.353245 │        0.176648 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┼─────────────────┤\n",
      "│ total_nmi │  0.568068 │             0.633692 │             0.601595 │        0.408318 │\n",
      "╘═══════════╧═══════════╧══════════════════════╧══════════════════════╧═════════════════╛\n",
      "╒═══════════╤════════════╤═══════════════════════╤═══════════════════════╤══════════════════╕\n",
      "│           │   cnn-test │   cnn_share_attn-test │   cnn_split_attn-test │   vit_share-test │\n",
      "╞═══════════╪════════════╪═══════════════════════╪═══════════════════════╪══════════════════╡\n",
      "│ Top_1     │   0.747842 │              0.723141 │              0.723861 │         0.598441 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ Top_3     │   0.754436 │              0.736211 │              0.723501 │         0.611631 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ Top_5     │   0.745803 │              0.726978 │              0.71307  │         0.603597 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ Top_7     │   0.744125 │              0.726379 │              0.711511 │         0.601918 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ Top_10    │   0.744005 │              0.726499 │              0.711511 │         0.601799 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ mean_ap   │   0.774873 │              0.754167 │              0.747398 │         0.642244 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ total_ari │   0.317524 │              0.370001 │              0.345217 │         0.180633 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┼──────────────────┤\n",
      "│ total_nmi │   0.566106 │              0.605823 │              0.598453 │         0.397829 │\n",
      "╘═══════════╧════════════╧═══════════════════════╧═══════════════════════╧══════════════════╛\n"
     ]
    }
   ],
   "source": [
    "best_model = {\"cnn\" : 20, \"cnn_share_attn\" : 200, \"cnn_split_attn\" : 140, \"vit_share\" : 40}\n",
    "\n",
    "\n",
    "\n",
    "for s in [\"val\", \"test\"]:\n",
    "    show_data = {}\n",
    "    for m in sorted(all_data.keys()):\n",
    "\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            if num != best_model[m]:\n",
    "                continue\n",
    "            \n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "            nn_class = labels[idx][indices]\n",
    "\n",
    "            mean_ap = mean_average_precision(nn_class, labels[idx])\n",
    "            \n",
    "\n",
    "            kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "            tp, tn, fp, fn = confusion(labels[idx], kmeans.labels_)\n",
    "            total_ari = adjusted_rand_score(labels[idx], kmeans.labels_)\n",
    "            total_nmi = normalized_mutual_info_score(labels[idx], kmeans.labels_)\n",
    "\n",
    "\n",
    "\n",
    "            show_data[f\"{m}-{s}\"] = [most_vote(nn_class, labels[idx], k) / nn_class.shape[0] for k in ks] + [mean_ap, total_ari, total_nmi] \n",
    "                \n",
    "\n",
    "\n",
    "    pd.set_option(\"display.precision\", 2)\n",
    "    df = pd.DataFrame(data=show_data, index=[f\"Top_{k}\" for k in ks] + [\"mean_ap\", \"total_ari\", \"total_nmi\"])\n",
    "\n",
    "    print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_data = {}\n",
    "# for idx in range(num_test):\n",
    "#     kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "#     acc = []\n",
    "#     total_mis = 0\n",
    "#     clusters = []\n",
    "#     new_cluster, cluster_map = map_label(kmeans.labels_, labels[idx])\n",
    "#     # cluster_map = {classes[old] : new for old, new in cluster_map.items()}\n",
    "#     # print(cluster_map)\n",
    "#     for i in range(len(classes)):\n",
    "#         mask = (labels[idx] == i)\n",
    "#         cluster = new_cluster[mask]\n",
    "#         cur_acc = (cluster == i).mean()\n",
    "#         acc.append(f\"{cur_acc: .2f}\")\n",
    "#         clusters.append(cluster)\n",
    "#         # if classes[i] == \"Violin_Mode\" or i == 0:\n",
    "#         #     print(kmeans.labels_[mask])\n",
    "\n",
    "#     cluster_class = classes\n",
    "#     # cluster_class = [\"\"] * len(classes)\n",
    "#     # for k,v in cluster_map.items():\n",
    "#     #     cluster_class[v] += f\"/{k}\"\n",
    "\n",
    "#     # for i in range(len(cluster_class)):\n",
    "#     #     if cluster_class[i] == \"\":\n",
    "#     #         cluster_class[i] = \"None\"\n",
    "\n",
    "\n",
    "#     show_data[f\"mAP_{20 * idx + 20}\"] = acc + [(new_cluster == labels[idx]).mean()]\n",
    "\n",
    "#     # print(cluster_map)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# mis_class = 0\n",
    "# mask = (labels == class_idx)\n",
    "# fname = np.array(fnames)[mask][clusters[class_idx] == mis_class]\n",
    "# print(fname.shape)\n",
    "# random.shuffle(fname)\n",
    "# data = [np.array(Image.open(fname[i][:-4].replace(\"test\", \"test_im\"))) for i in range(4)]\n",
    "# data = np.vstack(data)\n",
    "# fig = plt.figure(figsize=(30, 30)) \n",
    "# fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(data)\n",
    "# plt.title(f\"{class_idx}-{mis_class}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class_idx = 0\n",
    "# mis_class = 21\n",
    "# mask = (labels == class_idx)\n",
    "# fname = np.array(fnames)[mask][clusters[class_idx] == mis_class]\n",
    "# print(fname.shape)\n",
    "# random.shuffle(fname)\n",
    "\n",
    "# data = [np.array(Image.open(fname[i][:-4].replace(\"test\", \"test_im\"))) for i in range(4)]\n",
    "# data = np.vstack(data)\n",
    "# fig.add_subplot(1, 2, 2)\n",
    "# plt.imshow(data)\n",
    "# plt.title(f\"{class_idx}-{mis_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, cluster in enumerate(clusters):\n",
    "#     fig, ax = plt.subplots(figsize=(20, 10))\n",
    "#     counts, bins, patches = ax.hist(cluster, list(range(len(classes))))\n",
    "#     ax.set_title(classes[i])\n",
    "#     ax.set_xlabel(\"Cluster\")\n",
    "#     ax.set_ylabel(\"Number\")\n",
    "#     ax.set_xticks(bins + 0.5)\n",
    "#     ax.set_xticklabels(classes, rotation=60, ha=\"right\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[153], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m----> 2\u001b[0m x_embedded \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1110\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# TSNE.metric is not validated yet\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:820\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "x_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib._color_data as mcd\n",
    "palette = list(mcd.XKCD_COLORS.values())[::10]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:500, :]\n",
    "    plt.figure()\n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i])\n",
    "    plt.title(classes[i])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:50, :]\n",
    "    \n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:50, :].mean(0, keepdims=True)\n",
    "    \n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i], label=classes[i])\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:500, :]\n",
    "    # Configure the trace.\n",
    "    trace = go.Scatter3d(\n",
    "        x=x_show[:, 0],  \n",
    "        y=x_show[:, 1], \n",
    "        z=x_show[:, 2], \n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'opacity': 0.8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=Scene(\n",
    "                xaxis=XAxis(title=classes[i]),\n",
    "                yaxis=YAxis(title=classes[i]),\n",
    "                zaxis=ZAxis(title=classes[i])\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    # Render the plot.\n",
    "    plotly.offline.iplot(plot_figure)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:100, :]\n",
    "    cluster = kmeans.labels_[mask]\n",
    "    # mask = cluster == 14\n",
    "    # x_show = x_show[mask]\n",
    "    # Configure the trace.\n",
    "    trace = go.Scatter3d(\n",
    "        x=x_show[:, 0],  \n",
    "        y=x_show[:, 1], \n",
    "        z=x_show[:, 2], \n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'opacity': 0.8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=Scene(\n",
    "                xaxis=XAxis(title=classes[i]),\n",
    "                yaxis=YAxis(title=classes[i]),\n",
    "                zaxis=ZAxis(title=classes[i])\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data.append(trace)\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Render the plot.\n",
    "plotly.offline.iplot(plot_figure)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggin_face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
