{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, rand_score\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from munkres import Munkres\n",
    "from scipy.special import comb\n",
    "from PIL import Image\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tabulate import tabulate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_cost_matrix(c1, c2):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    uc1 = np.unique(c1)\n",
    "    uc2 = np.unique(c2)\n",
    "    l1 = uc1.size\n",
    "    l2 = uc2.size\n",
    "    assert(l1 == l2 and np.all(uc1 == uc2))\n",
    "\n",
    "    m = np.ones([l1, l2])\n",
    "    for i in range(l1):\n",
    "        it_i = np.nonzero(c1 == uc1[i])[0]\n",
    "        for j in range(l2):\n",
    "            it_j = np.nonzero(c2 == uc2[j])[0]\n",
    "            m_ij = np.intersect1d(it_j, it_i)\n",
    "            m[i,j] =  -m_ij.size\n",
    "    return m\n",
    "\n",
    "def translate_clustering(clt, mapper):\n",
    "    return np.array([ mapper[i] for i in clt ])\n",
    "\n",
    "\n",
    "\n",
    "def map_label(pred, gt):\n",
    "    \"\"\"entry point\"\"\"\n",
    "\n",
    "    num_labels = len(np.unique(gt))\n",
    "\n",
    "    # cm = confusion_matrix(gt, pred, labels=range(num_labels)) # gets the confusion matrix\n",
    "\n",
    "    cost_matrix = make_cost_matrix(pred, gt)\n",
    "\n",
    "    m = Munkres()\n",
    "    indexes = m.compute(cost_matrix)\n",
    "    mapper = { old: new for (old, new) in indexes }\n",
    "\n",
    "\n",
    "    new_labels = translate_clustering(pred, mapper)\n",
    "    new_cm = confusion_matrix(gt, new_labels, labels=range(num_labels))\n",
    "    return new_labels, mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_vote(nn_class, labels, k):\n",
    "    cur = 0\n",
    "    for i in range(nn_class.shape[0]):\n",
    "        max_num = 0\n",
    "        for j in range(k):\n",
    "            if ((nn_class[i, :] == nn_class[i, j]).sum() > max_num) or \\\n",
    "            (k > 1 and (nn_class[i, :] == nn_class[i, j]).sum() == max_num and nn_class[i, j] != labels[i]):\n",
    "                max_num = (nn_class[i, :] == nn_class[i, j]).sum()\n",
    "                max_class = nn_class[i, j]\n",
    "        \n",
    "        if max_class == labels[i]:\n",
    "            cur += 1\n",
    "    return cur\n",
    "\n",
    "\n",
    "def mean_average_precision(index, label):\n",
    "    correct = (index == label[:, None]).astype(np.int32)\n",
    "    precision = np.cumsum(correct, 1) / (np.arange(index.shape[1])[None, :] + 1)\n",
    "    res = (precision * correct).sum(1) / (correct.sum(1) + 1e-6)\n",
    "    return res.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_code/cnn_share_attn/val\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latent_code/cnn_share_attn/test\n",
      "\n",
      "latent_code/cnn_split_attn/val\n",
      "\n",
      "latent_code/cnn_split_attn/test\n",
      "\n",
      "latent_code/cnn/val\n",
      "\n",
      "latent_code/cnn/test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "all_data = {}\n",
    "for model_dir in os.listdir(\"latent_code\"):\n",
    "    all_data[model_dir] = {}\n",
    "    for s in [\"val\", \"test\"]:\n",
    "        test_dir = os.path.join(\"latent_code\", model_dir, s)\n",
    "\n",
    "        num_test = len(os.listdir(test_dir)) // 2\n",
    "\n",
    "        classes = [dir for dir in os.listdir(f\"{test_dir}/test_0\")]\n",
    "        classes.sort()\n",
    "        print(test_dir)\n",
    "        print()\n",
    "\n",
    "        data = []\n",
    "        labels = []\n",
    "        fnames = []\n",
    "\n",
    "        idx_num = [int(fname.split(\"_\")[-1]) for fname in os.listdir(f\"{test_dir}\") if \"im\" not in fname]\n",
    "        idx_num.sort()\n",
    "        num_file = 0\n",
    "        for i, dir in enumerate(classes):\n",
    "            _dir = os.path.join(f\"{test_dir}/test_0\")\n",
    "            for fname in os.listdir(os.path.join(_dir, dir)):\n",
    "                num_file += 1\n",
    "\n",
    "\n",
    "        shuffle_idx = np.arange(num_file)\n",
    "        np.random.shuffle(shuffle_idx)\n",
    "\n",
    "\n",
    "\n",
    "        for idx in idx_num:\n",
    "            data_tmp = []\n",
    "            label_tmp = []\n",
    "            fnames_tmp = []\n",
    "            for i, dir in enumerate(classes):\n",
    "                _dir = os.path.join(f\"{test_dir}/test_{idx}\")\n",
    "                for fname in os.listdir(os.path.join(_dir, dir)):\n",
    "                    data_tmp.append(np.load(os.path.join(_dir, dir, fname)))\n",
    "                    label_tmp.append(i)\n",
    "                    fnames_tmp.append(os.path.join(_dir, dir, fname))\n",
    "\n",
    "            data.append(np.vstack(data_tmp)[shuffle_idx, :])\n",
    "            labels.append(np.array(label_tmp)[shuffle_idx])\n",
    "            fnames.append(np.array(fnames_tmp)[shuffle_idx])\n",
    "        all_data[model_dir][s] = dict(data=data, labels=labels, fnames=fnames, idx_num=idx_num)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.491005 │ 0.78604  │ 0.734709 │ 0.711681 │ 0.69729  │ 0.694891 │ 0.692492 │ 0.686735 │ 0.682898 │ 0.683377 │ 0.684817 │ 0.681938 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.465339 │ 0.782202 │ 0.728952 │ 0.693692 │ 0.686256 │ 0.688414 │ 0.682898 │ 0.6793   │ 0.677621 │ 0.675222 │ 0.679779 │ 0.674502 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.49988  │ 0.783881 │ 0.73207  │ 0.693452 │ 0.688175 │ 0.687695 │ 0.684817 │ 0.686496 │ 0.679539 │ 0.681219 │ 0.684817 │ 0.67906  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.505877 │ 0.78628  │ 0.733989 │ 0.700648 │ 0.69633  │ 0.688894 │ 0.683137 │ 0.693692 │ 0.691533 │ 0.685536 │ 0.691533 │ 0.684337 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.519309 │ 0.776925 │ 0.722236 │ 0.69681  │ 0.684577 │ 0.680739 │ 0.677381 │ 0.682418 │ 0.682178 │ 0.680019 │ 0.681458 │ 0.674502 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.505036 │ 0.788849 │ 0.747842 │ 0.726259 │ 0.711151 │ 0.707914 │ 0.708153 │ 0.705156 │ 0.703597 │ 0.699281 │ 0.703597 │ 0.705156 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.480096 │ 0.792926 │ 0.740767 │ 0.71211  │ 0.704556 │ 0.699161 │ 0.703957 │ 0.701799 │ 0.697122 │ 0.696523 │ 0.7      │ 0.697002 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.501199 │ 0.796882 │ 0.745444 │ 0.714508 │ 0.706235 │ 0.702638 │ 0.705516 │ 0.705036 │ 0.702398 │ 0.698321 │ 0.704197 │ 0.702038 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.51211  │ 0.797002 │ 0.74964  │ 0.726619 │ 0.717266 │ 0.71235  │ 0.709712 │ 0.715348 │ 0.707314 │ 0.702158 │ 0.708393 │ 0.710312 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.527938 │ 0.793405 │ 0.744005 │ 0.720504 │ 0.705755 │ 0.703597 │ 0.70036  │ 0.703477 │ 0.696882 │ 0.694365 │ 0.699281 │ 0.701079 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.349964 │ 0.722955 │ 0.769729 │ 0.760614 │ 0.727273 │ 0.720796 │ 0.712401 │ 0.723675 │ 0.71408  │ 0.71504  │ 0.719117 │ 0.71408  │ 0.717438 │ 0.720317 │ 0.723195 │ 0.719837 │ 0.721756 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.279923 │ 0.720556 │ 0.762053 │ 0.754378 │ 0.712641 │ 0.707604 │ 0.707844 │ 0.710002 │ 0.705685 │ 0.706404 │ 0.712641 │ 0.709763 │ 0.711202 │ 0.717678 │ 0.709523 │ 0.7136   │ 0.710962 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.342048 │ 0.727273 │ 0.769489 │ 0.755817 │ 0.718158 │ 0.712161 │ 0.701607 │ 0.713361 │ 0.702327 │ 0.702806 │ 0.716959 │ 0.71456  │ 0.713121 │ 0.721036 │ 0.7148   │ 0.711202 │ 0.71456  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.345646 │ 0.730871 │ 0.772367 │ 0.761094 │ 0.718877 │ 0.710482 │ 0.703766 │ 0.720556 │ 0.706884 │ 0.712401 │ 0.719837 │ 0.717918 │ 0.715759 │ 0.721036 │ 0.719597 │ 0.722715 │ 0.718158 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.372511 │ 0.727513 │ 0.761574 │ 0.744303 │ 0.712641 │ 0.700168 │ 0.69609  │ 0.702806 │ 0.69705  │ 0.69705  │ 0.708563 │ 0.709763 │ 0.710242 │ 0.711681 │ 0.712161 │ 0.710722 │ 0.708803 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.341607 │ 0.73717  │ 0.780216 │ 0.764269 │ 0.727818 │ 0.728058 │ 0.722662 │ 0.735012 │ 0.721823 │ 0.720144 │ 0.735252 │ 0.723141 │ 0.729976 │ 0.731894 │ 0.730216 │ 0.733213 │ 0.731775 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.276619 │ 0.741607 │ 0.781535 │ 0.76295  │ 0.733933 │ 0.726379 │ 0.721942 │ 0.731055 │ 0.723141 │ 0.721223 │ 0.734293 │ 0.72458  │ 0.727338 │ 0.727578 │ 0.727458 │ 0.734053 │ 0.731535 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.338249 │ 0.741607 │ 0.788489 │ 0.772182 │ 0.738969 │ 0.730935 │ 0.729257 │ 0.734532 │ 0.722422 │ 0.723501 │ 0.73789  │ 0.7253   │ 0.732494 │ 0.73693  │ 0.733213 │ 0.736451 │ 0.735851 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.353837 │ 0.748201 │ 0.792206 │ 0.77446  │ 0.747362 │ 0.73801  │ 0.736091 │ 0.745444 │ 0.734772 │ 0.73801  │ 0.745803 │ 0.732494 │ 0.738249 │ 0.740288 │ 0.741247 │ 0.746643 │ 0.740647 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.379257 │ 0.742806 │ 0.786571 │ 0.763189 │ 0.739688 │ 0.729376 │ 0.727218 │ 0.73753  │ 0.724221 │ 0.72494  │ 0.730096 │ 0.726499 │ 0.729736 │ 0.732374 │ 0.730336 │ 0.732134 │ 0.733333 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.333893 │ 0.753898 │ 0.735428 │ 0.715279 │ 0.703046 │ 0.701607 │ 0.699448 │ 0.699688 │ 0.690813 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.271768 │ 0.754378 │ 0.720556 │ 0.691773 │ 0.69561  │ 0.693212 │ 0.698009 │ 0.69561  │ 0.695371 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.328376 │ 0.753418 │ 0.718398 │ 0.692252 │ 0.693212 │ 0.695371 │ 0.694411 │ 0.69657  │ 0.700648 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.337491 │ 0.757976 │ 0.720317 │ 0.706165 │ 0.700168 │ 0.702327 │ 0.705685 │ 0.704725 │ 0.707604 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.361717 │ 0.754857 │ 0.712401 │ 0.69681  │ 0.693931 │ 0.690094 │ 0.692012 │ 0.69561  │ 0.692732 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│       │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ Top1  │ 0.347962 │ 0.769305 │ 0.739448 │ 0.722422 │ 0.724221 │ 0.722182 │ 0.719784 │ 0.722182 │ 0.723861 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top3  │ 0.278537 │ 0.768945 │ 0.738249 │ 0.719065 │ 0.713669 │ 0.71247  │ 0.713309 │ 0.709592 │ 0.711151 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top5  │ 0.330096 │ 0.776139 │ 0.739808 │ 0.718705 │ 0.716427 │ 0.716187 │ 0.71271  │ 0.715588 │ 0.714508 │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top7  │ 0.341966 │ 0.780336 │ 0.747962 │ 0.733813 │ 0.726859 │ 0.723741 │ 0.718945 │ 0.721942 │ 0.72542  │\n",
      "├───────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ Top10 │ 0.367626 │ 0.77506  │ 0.743885 │ 0.720863 │ 0.716427 │ 0.710911 │ 0.711751 │ 0.713429 │ 0.711511 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "for m in sorted(all_data.keys()):\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "\n",
    "            # for k in ks:\n",
    "\n",
    "            #     index = indices[:, :k]\n",
    "            #     nn_class = labels[idx][index]\n",
    "            #     acc = []\n",
    "                \n",
    "            #     for c in range(len(classes)):\n",
    "            #         cur = 0\n",
    "            #         mask = (labels[idx] == c)\n",
    "            #         nn_class_msk = nn_class[mask]\n",
    "            #         cur = most_vote(nn_class_msk, labels[idx][mask], k)\n",
    "                    \n",
    "            #         acc.append(cur / nn_class_msk.shape[0])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            #     total_acc = most_vote(nn_class, labels[idx], k) / nn_class.shape[0]\n",
    "\n",
    "\n",
    "            #     # show_data[f\"Top{k}_{num}\"] =  acc + [total_acc] \n",
    "            #     show_data[f\"Top{k}_{num}\"] =  [total_acc] \n",
    "\n",
    "\n",
    "\n",
    "            acc = []\n",
    "            for k in ks:\n",
    "\n",
    "                index = indices[:, :k]\n",
    "                nn_class = labels[idx][index]\n",
    "                \n",
    "            \n",
    "                total_acc = most_vote(nn_class, labels[idx], k) / nn_class.shape[0]\n",
    "                acc.append(total_acc)\n",
    "\n",
    "            show_data[f\"{num}\"] =  acc\n",
    "\n",
    "\n",
    "\n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "        # df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "        df = pd.DataFrame(data=show_data, index=[f\"Top{k}\" for k in ks])\n",
    "        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.562286 │ 0.806557 │ 0.763926 │ 0.737759 │ 0.727211 │ 0.724302 │  0.724665 │  0.722477 │  0.720352 │  0.717085 │  0.719464 │  0.718865 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.572765 │ 0.815378 │ 0.774873 │ 0.750443 │ 0.741364 │ 0.738706 │  0.739291 │  0.739238 │  0.736196 │  0.734198 │  0.736799 │   0.73615 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_share_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │   mAP_220 │   mAP_240 │   mAP_260 │   mAP_280 │   mAP_300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.438644 │ 0.758745 │ 0.794347 │ 0.785209 │ 0.750883 │ 0.749034 │  0.742541 │   0.75038 │   0.74029 │  0.739723 │  0.746478 │  0.741855 │  0.743439 │   0.74582 │  0.745097 │  0.746352 │  0.745508 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_share_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │   mAP_160 │   mAP_180 │   mAP_200 │   mAP_220 │   mAP_240 │   mAP_260 │   mAP_280 │   mAP_300 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.442732 │ 0.773245 │ 0.807204 │ 0.794759 │ 0.765211 │ 0.760808 │  0.756254 │  0.763001 │  0.752644 │  0.753162 │  0.761451 │  0.754167 │  0.758547 │  0.759436 │  0.758729 │  0.762895 │  0.760188 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_split_attn-val================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.427438 │ 0.784775 │ 0.760907 │ 0.742011 │ 0.737158 │ 0.735218 │  0.734769 │  0.734084 │  0.730952 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╛\n",
      "=============================cnn_split_attn-test================================================\n",
      "╒═══════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤═══════════╤═══════════╤═══════════╕\n",
      "│       │    mAP_0 │   mAP_10 │   mAP_20 │   mAP_40 │   mAP_60 │   mAP_80 │   mAP_100 │   mAP_120 │   mAP_140 │\n",
      "╞═══════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪═══════════╪═══════════╪═══════════╡\n",
      "│ total │ 0.440743 │ 0.797459 │ 0.772386 │ 0.753872 │ 0.750678 │ 0.747252 │  0.746626 │  0.747226 │  0.747398 │\n",
      "╘═══════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧═══════════╧═══════════╧═══════════╛\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for m in sorted(all_data.keys()):\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            \n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "\n",
    "            nn_class = labels[idx][indices]\n",
    "            acc = []\n",
    "            \n",
    "            for c in range(len(classes)):\n",
    "                mask = (labels[idx] == c)\n",
    "                nn_class_msk = nn_class[mask]\n",
    "                cur = mean_average_precision(nn_class_msk, labels[idx][mask])\n",
    "                acc.append(cur)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            total_acc = mean_average_precision(nn_class, labels[idx])\n",
    "\n",
    "\n",
    "            # show_data[f\"mAP_{num}\"] =  acc + [total_acc] \n",
    "            show_data[f\"mAP_{num}\"] =  [total_acc] \n",
    "                \n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "\n",
    "        # df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "        df = pd.DataFrame(data=show_data, index=[\"total\"])\n",
    "        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=============================cnn-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.386462 │ 0.475839 │ 0.412093 │ 0.404289 │ 0.37718  │ 0.399692 │ 0.380927 │ 0.401975 │ 0.341593 │ 0.347835 │ 0.362994 │ 0.398183 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.195213 │ 0.260755 │ 0.345353 │ 0.27889  │ 0.32773  │ 0.326388 │ 0.321026 │ 0.319989 │ 0.352241 │ 0.344524 │ 0.359546 │ 0.347557 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.865838 │ 0.886119 │ 0.916767 │ 0.900231 │ 0.915097 │ 0.913354 │ 0.913382 │ 0.911709 │ 0.921781 │ 0.920118 │ 0.921963 │ 0.917969 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.19431  │ 0.280369 │ 0.331564 │ 0.27814  │ 0.305539 │ 0.313382 │ 0.30239  │ 0.309586 │ 0.305246 │ 0.303633 │ 0.319705 │ 0.32749  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.458957 │ 0.557677 │ 0.591305 │ 0.562206 │ 0.564864 │ 0.572521 │ 0.575271 │ 0.569981 │ 0.571378 │ 0.567326 │ 0.588968 │ 0.582244 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.422823 │ 0.441638 │ 0.398851 │ 0.383871 │ 0.382553 │ 0.376513 │ 0.348859 │ 0.367364 │ 0.341208 │ 0.380139 │ 0.33088  │ 0.362544 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.173234 │ 0.313591 │ 0.288098 │ 0.262856 │ 0.322299 │ 0.349224 │ 0.338063 │ 0.335144 │ 0.373737 │ 0.344493 │ 0.349621 │ 0.35795  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.841961 │ 0.907127 │ 0.903371 │ 0.896921 │ 0.913412 │ 0.919303 │ 0.918748 │ 0.917092 │ 0.925062 │ 0.918201 │ 0.921768 │ 0.921578 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.174446 │ 0.3182   │ 0.283907 │ 0.258431 │ 0.303831 │ 0.319346 │ 0.300082 │ 0.306335 │ 0.317033 │ 0.317854 │ 0.298445 │ 0.318463 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.434472 │ 0.580822 │ 0.561235 │ 0.534366 │ 0.568413 │ 0.576921 │ 0.559582 │ 0.576273 │ 0.572781 │ 0.569405 │ 0.561884 │ 0.578634 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.241672 │ 0.509263 │ 0.499881 │ 0.439605 │ 0.465279 │ 0.439044 │ 0.474356 │ 0.481852 │ 0.469165 │ 0.455697 │ 0.437392 │ 0.478221 │ 0.415822 │ 0.429908 │ 0.423999 │ 0.425309 │ 0.470409 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.176428 │ 0.204442 │ 0.303572 │ 0.373822 │ 0.309107 │ 0.37662  │ 0.339254 │ 0.34753  │ 0.3215   │ 0.424987 │ 0.405895 │ 0.440903 │ 0.397954 │ 0.397348 │ 0.388706 │ 0.406698 │ 0.407342 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.885311 │ 0.849685 │ 0.899876 │ 0.921162 │ 0.904267 │ 0.921716 │ 0.911876 │ 0.9135   │ 0.907532 │ 0.929424 │ 0.926874 │ 0.931411 │ 0.926239 │ 0.9257   │ 0.924443 │ 0.92734  │ 0.926194 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.143782 │ 0.224473 │ 0.326818 │ 0.362138 │ 0.321906 │ 0.363806 │ 0.349472 │ 0.358497 │ 0.333452 │ 0.402195 │ 0.382085 │ 0.422254 │ 0.367387 │ 0.373393 │ 0.365325 │ 0.377077 │ 0.397338 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.366759 │ 0.511141 │ 0.58665  │ 0.604971 │ 0.592434 │ 0.60373  │ 0.603192 │ 0.608114 │ 0.598732 │ 0.623327 │ 0.623414 │ 0.647603 │ 0.606121 │ 0.615708 │ 0.602044 │ 0.615463 │ 0.624033 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_share_attn-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │      160 │      180 │      200 │      220 │      240 │      260 │      280 │      300 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.239598 │ 0.494615 │ 0.459122 │ 0.430087 │ 0.48361  │ 0.408714 │ 0.455099 │ 0.42176  │ 0.456233 │ 0.430699 │ 0.44826  │ 0.465378 │ 0.417625 │ 0.428243 │ 0.426883 │ 0.43649  │ 0.410869 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.186988 │ 0.183421 │ 0.312227 │ 0.381876 │ 0.390128 │ 0.35414  │ 0.363799 │ 0.380703 │ 0.39319  │ 0.379407 │ 0.393225 │ 0.424571 │ 0.370398 │ 0.437189 │ 0.423889 │ 0.398213 │ 0.380505 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.890251 │ 0.835125 │ 0.905471 │ 0.922898 │ 0.922513 │ 0.918599 │ 0.918349 │ 0.923005 │ 0.924007 │ 0.922428 │ 0.924277 │ 0.929032 │ 0.921304 │ 0.931608 │ 0.929766 │ 0.925513 │ 0.923386 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.152041 │ 0.196186 │ 0.322577 │ 0.363486 │ 0.390799 │ 0.336155 │ 0.361114 │ 0.359159 │ 0.381939 │ 0.362124 │ 0.378627 │ 0.406221 │ 0.350684 │ 0.396285 │ 0.387979 │ 0.37678  │ 0.354272 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.365058 │ 0.493272 │ 0.584367 │ 0.602992 │ 0.612519 │ 0.589432 │ 0.59947  │ 0.603659 │ 0.620813 │ 0.612943 │ 0.611646 │ 0.633829 │ 0.597271 │ 0.626519 │ 0.618675 │ 0.612006 │ 0.598211 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-val================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.210765 │ 0.525905 │ 0.463745 │ 0.394825 │ 0.395573 │ 0.376853 │ 0.356607 │ 0.422077 │ 0.40196  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.160005 │ 0.200196 │ 0.285146 │ 0.321214 │ 0.356557 │ 0.369916 │ 0.344029 │ 0.394833 │ 0.403931 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.884749 │ 0.843443 │ 0.896717 │ 0.912484 │ 0.919855 │ 0.923091 │ 0.919546 │ 0.925535 │ 0.92758  │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.121167 │ 0.221432 │ 0.300479 │ 0.307829 │ 0.332358 │ 0.332387 │ 0.307338 │ 0.368316 │ 0.364396 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.330325 │ 0.525457 │ 0.575818 │ 0.573061 │ 0.590453 │ 0.587825 │ 0.571123 │ 0.611534 │ 0.613071 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n",
      "=============================cnn_split_attn-test================================================\n",
      "╒═════════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╤══════════╕\n",
      "│             │        0 │       10 │       20 │       40 │       60 │       80 │      100 │      120 │      140 │\n",
      "╞═════════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╪══════════╡\n",
      "│ precision   │ 0.251627 │ 0.535277 │ 0.39402  │ 0.387253 │ 0.347964 │ 0.381426 │ 0.369898 │ 0.363695 │ 0.378033 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ recall      │ 0.163343 │ 0.224684 │ 0.33264  │ 0.357633 │ 0.363527 │ 0.340685 │ 0.352812 │ 0.376079 │ 0.355031 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ accuracy    │ 0.875936 │ 0.859215 │ 0.914956 │ 0.920326 │ 0.923191 │ 0.917377 │ 0.920306 │ 0.924505 │ 0.920301 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ adjusted RI │ 0.134147 │ 0.252375 │ 0.315534 │ 0.329391 │ 0.314758 │ 0.315895 │ 0.318681 │ 0.329643 │ 0.323693 │\n",
      "├─────────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┼──────────┤\n",
      "│ nmi         │ 0.346806 │ 0.540788 │ 0.571302 │ 0.589568 │ 0.577147 │ 0.577571 │ 0.589669 │ 0.586636 │ 0.577802 │\n",
      "╘═════════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╧══════════╛\n"
     ]
    }
   ],
   "source": [
    "def confusion(actual, pred):\n",
    "\n",
    "    tp_plus_fp = comb(np.bincount(actual), 2).sum()\n",
    "    tp_plus_fn = comb(np.bincount(pred), 2).sum()\n",
    "    A = np.c_[(actual, pred)]\n",
    "    tp = sum(comb(np.bincount(A[A[:, 0] == i, 1]), 2).sum()\n",
    "             for i in set(actual))\n",
    "    fp = tp_plus_fp - tp\n",
    "    fn = tp_plus_fn - tp\n",
    "    tn = comb(len(A), 2) - tp - fp - fn\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "\n",
    "for m in sorted(all_data.keys()):\n",
    "    for s in all_data[m].keys():\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        show_data = {}\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "            tp, tn, fp, fn = confusion(labels[idx], kmeans.labels_)\n",
    "            total_prec = tp / (tp + fp)\n",
    "            total_rec = tp / (tp + fn)\n",
    "            total_acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "            total_ari = adjusted_rand_score(labels[idx], kmeans.labels_)\n",
    "            total_nmi = normalized_mutual_info_score(labels[idx], kmeans.labels_)\n",
    "\n",
    "            show_data[f\"{num}\"] = [f\"{total_prec}\", f\"{total_rec}\", f\"{total_acc}\", f\"{total_ari}\", f\"{total_nmi}\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "        print(f\"============================={m}-{s}================================================\")\n",
    "        df = pd.DataFrame(data=show_data, index=[\"precision\", \"recall\", \"accuracy\", \"adjusted RI\", \"nmi\"])\n",
    "        print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "╒═══════════╤═══════════╤══════════════════════╤══════════════════════╕\n",
      "│           │   cnn-val │   cnn_share_attn-val │   cnn_split_attn-val │\n",
      "╞═══════════╪═══════════╪══════════════════════╪══════════════════════╡\n",
      "│ Top_1     │  0.734709 │             0.71408  │             0.690813 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ Top_3     │  0.733509 │             0.720796 │             0.708083 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ Top_5     │  0.723675 │             0.709763 │             0.694891 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ Top_7     │  0.722236 │             0.709763 │             0.692732 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ Top_10    │  0.722236 │             0.709763 │             0.692732 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ mean_ap   │  0.763926 │             0.741855 │             0.730952 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ total_ari │  0.331564 │             0.422254 │             0.364396 │\n",
      "├───────────┼───────────┼──────────────────────┼──────────────────────┤\n",
      "│ total_nmi │  0.591305 │             0.647603 │             0.613071 │\n",
      "╘═══════════╧═══════════╧══════════════════════╧══════════════════════╛\n",
      "╒═══════════╤════════════╤═══════════════════════╤═══════════════════════╕\n",
      "│           │   cnn-test │   cnn_share_attn-test │   cnn_split_attn-test │\n",
      "╞═══════════╪════════════╪═══════════════════════╪═══════════════════════╡\n",
      "│ Top_1     │   0.747842 │              0.723141 │              0.723861 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ Top_3     │   0.754436 │              0.736211 │              0.723501 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ Top_5     │   0.745803 │              0.726978 │              0.71307  │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ Top_7     │   0.744125 │              0.726379 │              0.711511 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ Top_10    │   0.744005 │              0.726499 │              0.711511 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ mean_ap   │   0.774873 │              0.754167 │              0.747398 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ total_ari │   0.283907 │              0.406221 │              0.323693 │\n",
      "├───────────┼────────────┼───────────────────────┼───────────────────────┤\n",
      "│ total_nmi │   0.561235 │              0.633829 │              0.577802 │\n",
      "╘═══════════╧════════════╧═══════════════════════╧═══════════════════════╛\n"
     ]
    }
   ],
   "source": [
    "best_model = {\"cnn\" : 20, \"cnn_share_attn\" : 200, \"cnn_split_attn\" : 140}\n",
    "\n",
    "\n",
    "\n",
    "for s in [\"val\", \"test\"]:\n",
    "    show_data = {}\n",
    "    for m in sorted(all_data.keys()):\n",
    "\n",
    "        data = all_data[m][s][\"data\"]\n",
    "        labels = all_data[m][s][\"labels\"]\n",
    "        fnames = all_data[m][s][\"fnames\"]\n",
    "        idx_num = all_data[m][s][\"idx_num\"]\n",
    "        for idx, num in enumerate(idx_num):\n",
    "            if num != best_model[m]:\n",
    "                continue\n",
    "            \n",
    "            ks = [1, 3, 5, 7, 10]\n",
    "\n",
    "            knn = NearestNeighbors(n_neighbors=ks[-1] + 1, algorithm='brute').fit(data[idx])\n",
    "            distances, indices = knn.kneighbors(data[idx])\n",
    "            remove_idx = (indices == np.arange(indices.shape[0])[:, np.newaxis])\n",
    "            indices = indices[np.logical_not(remove_idx)].reshape(indices.shape[0], -1)\n",
    "\n",
    "            nn_class = labels[idx][indices]\n",
    "\n",
    "            mean_ap = mean_average_precision(nn_class, labels[idx])\n",
    "            \n",
    "\n",
    "            kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "            tp, tn, fp, fn = confusion(labels[idx], kmeans.labels_)\n",
    "            total_ari = adjusted_rand_score(labels[idx], kmeans.labels_)\n",
    "            total_nmi = normalized_mutual_info_score(labels[idx], kmeans.labels_)\n",
    "\n",
    "\n",
    "\n",
    "            show_data[f\"{m}-{s}\"] = [most_vote(nn_class, labels[idx], k) / nn_class.shape[0] for k in ks] + [mean_ap, total_ari, total_nmi] \n",
    "                \n",
    "\n",
    "\n",
    "    pd.set_option(\"display.precision\", 2)\n",
    "    df = pd.DataFrame(data=show_data, index=[f\"Top_{k}\" for k in ks] + [\"mean_ap\", \"total_ari\", \"total_nmi\"])\n",
    "\n",
    "    print(tabulate(df, headers='keys', tablefmt='fancy_grid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cnn_share_attn/val/test_260 : 4169\n",
      "cnn_share_attn/val/test_80 : 4169\n",
      "cnn_share_attn/val/test_180 : 4169\n",
      "cnn_share_attn/val/test_100 : 4169\n",
      "cnn_share_attn/val/test_300 : 4169\n",
      "cnn_share_attn/val/test_0 : 4169\n",
      "cnn_share_attn/val/test_10 : 4169\n",
      "cnn_share_attn/val/test_160 : 4169\n",
      "cnn_share_attn/val/test_280 : 4169\n",
      "cnn_share_attn/val/test_60 : 4169\n",
      "cnn_share_attn/val/test_200 : 4169\n",
      "cnn_share_attn/val/test_120 : 4169\n",
      "cnn_share_attn/val/test_20 : 4169\n",
      "cnn_share_attn/val/test_240 : 4169\n",
      "cnn_share_attn/val/test_40 : 4169\n",
      "cnn_share_attn/val/test_220 : 4169\n",
      "cnn_share_attn/val/test_140 : 4169\n",
      "cnn_share_attn/test/test_10 : 8340\n",
      "cnn_share_attn/test/test_260 : 8340\n",
      "cnn_share_attn/test/test_180 : 8340\n",
      "cnn_share_attn/test/test_60 : 8340\n",
      "cnn_share_attn/test/test_100 : 8340\n",
      "cnn_share_attn/test/test_300 : 8340\n",
      "cnn_share_attn/test/test_80 : 8340\n",
      "cnn_share_attn/test/test_160 : 8340\n",
      "cnn_share_attn/test/test_0 : 8340\n",
      "cnn_share_attn/test/test_280 : 8340\n",
      "cnn_share_attn/test/test_200 : 8340\n",
      "cnn_share_attn/test/test_40 : 8340\n",
      "cnn_share_attn/test/test_120 : 8340\n",
      "cnn_share_attn/test/test_240 : 8340\n",
      "cnn_share_attn/test/test_220 : 8340\n",
      "cnn_share_attn/test/test_20 : 8340\n",
      "cnn_share_attn/test/test_140 : 8340\n",
      "cnn_split_attn/val/test_0 : 4169\n",
      "cnn_split_attn/val/test_40 : 4169\n",
      "cnn_split_attn/val/test_120 : 4169\n",
      "cnn_split_attn/val/test_140 : 4169\n",
      "cnn_split_attn/val/test_20 : 4169\n",
      "cnn_split_attn/val/test_10 : 4169\n",
      "cnn_split_attn/val/test_100 : 4169\n",
      "cnn_split_attn/val/test_60 : 4169\n",
      "cnn_split_attn/val/test_80 : 4169\n",
      "cnn_split_attn/test/test_10 : 8340\n",
      "cnn_split_attn/test/test_60 : 8340\n",
      "cnn_split_attn/test/test_140 : 8340\n",
      "cnn_split_attn/test/test_120 : 8340\n",
      "cnn_split_attn/test/test_80 : 8340\n",
      "cnn_split_attn/test/test_0 : 8340\n",
      "cnn_split_attn/test/test_40 : 8340\n",
      "cnn_split_attn/test/test_20 : 8340\n",
      "cnn_split_attn/test/test_100 : 8340\n",
      "cnn/val/test_120 : 4169\n",
      "cnn/val/test_40 : 4169\n",
      "cnn/val/test_20 : 4169\n",
      "cnn/val/test_140 : 4169\n",
      "cnn/val/test_60 : 4169\n",
      "cnn/val/test_0 : 4169\n",
      "cnn/val/test_180 : 4169\n",
      "cnn/val/test_10 : 4169\n",
      "cnn/val/test_100 : 4169\n",
      "cnn/val/test_160 : 4169\n",
      "cnn/val/test_80 : 4169\n",
      "cnn/val/test_200 : 4169\n",
      "cnn/test/test_10 : 8340\n",
      "cnn/test/test_140 : 8340\n",
      "cnn/test/test_0 : 8340\n",
      "cnn/test/test_60 : 8340\n",
      "cnn/test/test_80 : 8340\n",
      "cnn/test/test_120 : 8340\n",
      "cnn/test/test_40 : 8340\n",
      "cnn/test/test_200 : 8340\n",
      "cnn/test/test_160 : 8340\n",
      "cnn/test/test_180 : 8340\n",
      "cnn/test/test_100 : 8340\n",
      "cnn/test/test_20 : 8340\n"
     ]
    }
   ],
   "source": [
    "for m in all_data.keys():\n",
    "    for s in all_data[m].keys():\n",
    "        for dir in os.listdir(os.path.join(\"latent_code\", m, s)):\n",
    "            if \"im\" in dir:\n",
    "                continue\n",
    "            count = sum([len(list(os.listdir(os.path.join(\"latent_code\", m, s, dir, i)))) for i in os.listdir(os.path.join(\"latent_code\", m, s, dir))])\n",
    "            print(f\"{os.path.join(m, s, dir)} : {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show_data = {}\n",
    "# for idx in range(num_test):\n",
    "#     kmeans = KMeans(n_clusters=len(classes), random_state=0, n_init=\"auto\").fit(data[idx])\n",
    "#     acc = []\n",
    "#     total_mis = 0\n",
    "#     clusters = []\n",
    "#     new_cluster, cluster_map = map_label(kmeans.labels_, labels[idx])\n",
    "#     # cluster_map = {classes[old] : new for old, new in cluster_map.items()}\n",
    "#     # print(cluster_map)\n",
    "#     for i in range(len(classes)):\n",
    "#         mask = (labels[idx] == i)\n",
    "#         cluster = new_cluster[mask]\n",
    "#         cur_acc = (cluster == i).mean()\n",
    "#         acc.append(f\"{cur_acc: .2f}\")\n",
    "#         clusters.append(cluster)\n",
    "#         # if classes[i] == \"Violin_Mode\" or i == 0:\n",
    "#         #     print(kmeans.labels_[mask])\n",
    "\n",
    "#     cluster_class = classes\n",
    "#     # cluster_class = [\"\"] * len(classes)\n",
    "#     # for k,v in cluster_map.items():\n",
    "#     #     cluster_class[v] += f\"/{k}\"\n",
    "\n",
    "#     # for i in range(len(cluster_class)):\n",
    "#     #     if cluster_class[i] == \"\":\n",
    "#     #         cluster_class[i] = \"None\"\n",
    "\n",
    "\n",
    "#     show_data[f\"mAP_{20 * idx + 20}\"] = acc + [(new_cluster == labels[idx]).mean()]\n",
    "\n",
    "#     # print(cluster_map)\n",
    "\n",
    "\n",
    "# df = pd.DataFrame(data=show_data, index=classes + [\"total\"])\n",
    "# print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_idx = 0\n",
    "# mis_class = 0\n",
    "# mask = (labels == class_idx)\n",
    "# fname = np.array(fnames)[mask][clusters[class_idx] == mis_class]\n",
    "# print(fname.shape)\n",
    "# random.shuffle(fname)\n",
    "# data = [np.array(Image.open(fname[i][:-4].replace(\"test\", \"test_im\"))) for i in range(4)]\n",
    "# data = np.vstack(data)\n",
    "# fig = plt.figure(figsize=(30, 30)) \n",
    "# fig.add_subplot(1, 2, 1)\n",
    "# plt.imshow(data)\n",
    "# plt.title(f\"{class_idx}-{mis_class}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# class_idx = 0\n",
    "# mis_class = 21\n",
    "# mask = (labels == class_idx)\n",
    "# fname = np.array(fnames)[mask][clusters[class_idx] == mis_class]\n",
    "# print(fname.shape)\n",
    "# random.shuffle(fname)\n",
    "\n",
    "# data = [np.array(Image.open(fname[i][:-4].replace(\"test\", \"test_im\"))) for i in range(4)]\n",
    "# data = np.vstack(data)\n",
    "# fig.add_subplot(1, 2, 2)\n",
    "# plt.imshow(data)\n",
    "# plt.title(f\"{class_idx}-{mis_class}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, cluster in enumerate(clusters):\n",
    "#     fig, ax = plt.subplots(figsize=(20, 10))\n",
    "#     counts, bins, patches = ax.hist(cluster, list(range(len(classes))))\n",
    "#     ax.set_title(classes[i])\n",
    "#     ax.set_xlabel(\"Cluster\")\n",
    "#     ax.set_ylabel(\"Number\")\n",
    "#     ax.set_xticks(bins + 0.5)\n",
    "#     ax.set_xticklabels(classes, rotation=60, ha=\"right\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[123], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmanifold\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TSNE\n\u001b[0;32m----> 2\u001b[0m x_embedded \u001b[38;5;241m=\u001b[39m \u001b[43mTSNE\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mauto\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m                  \u001b[49m\u001b[43minit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrandom\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperplexity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1150\u001b[0m     )\n\u001b[1;32m   1151\u001b[0m ):\n\u001b[0;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:1110\u001b[0m, in \u001b[0;36mTSNE.fit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(\n\u001b[1;32m   1086\u001b[0m     \u001b[38;5;66;03m# TSNE.metric is not validated yet\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m     prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1088\u001b[0m )\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit X into an embedded space and return that transformed output.\u001b[39;00m\n\u001b[1;32m   1091\u001b[0m \n\u001b[1;32m   1092\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[38;5;124;03m        Embedding of the training data in low-dimensional space.\u001b[39;00m\n\u001b[1;32m   1109\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1110\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params_vs_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1111\u001b[0m     embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fit(X)\n\u001b[1;32m   1112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding_ \u001b[38;5;241m=\u001b[39m embedding\n",
      "File \u001b[0;32m~/.conda/envs/huggin_face/lib/python3.8/site-packages/sklearn/manifold/_t_sne.py:820\u001b[0m, in \u001b[0;36mTSNE._check_params_vs_input\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    819\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_params_vs_input\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m--> 820\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mperplexity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m[\u001b[38;5;241m0\u001b[39m]:\n\u001b[1;32m    821\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mperplexity must be less than n_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "x_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib._color_data as mcd\n",
    "palette = list(mcd.XKCD_COLORS.values())[::10]\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:500, :]\n",
    "    plt.figure()\n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i])\n",
    "    plt.title(classes[i])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:50, :]\n",
    "    \n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i])\n",
    "\n",
    "plt.figure()\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:50, :].mean(0, keepdims=True)\n",
    "    \n",
    "    plt.scatter(x_show[:, 0], x_show[:, 1], color=palette[3 * i], label=classes[i])\n",
    "    plt.legend(bbox_to_anchor=(1.1, 1.05))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_embedded = TSNE(n_components=3, learning_rate='auto',\n",
    "                  init='random', perplexity=3).fit_transform(data)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "from plotly.graph_objs import *\n",
    "\n",
    "# Configure Plotly to be rendered inline in the notebook.\n",
    "plotly.offline.init_notebook_mode()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:500, :]\n",
    "    # Configure the trace.\n",
    "    trace = go.Scatter3d(\n",
    "        x=x_show[:, 0],  \n",
    "        y=x_show[:, 1], \n",
    "        z=x_show[:, 2], \n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'opacity': 0.8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=Scene(\n",
    "                xaxis=XAxis(title=classes[i]),\n",
    "                yaxis=YAxis(title=classes[i]),\n",
    "                zaxis=ZAxis(title=classes[i])\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data = [trace]\n",
    "\n",
    "    plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "    # Render the plot.\n",
    "    plotly.offline.iplot(plot_figure)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for i in range(len(classes)):\n",
    "    mask = (labels == i)\n",
    "    x_show = x_embedded[mask, :][:100, :]\n",
    "    cluster = kmeans.labels_[mask]\n",
    "    # mask = cluster == 14\n",
    "    # x_show = x_show[mask]\n",
    "    # Configure the trace.\n",
    "    trace = go.Scatter3d(\n",
    "        x=x_show[:, 0],  \n",
    "        y=x_show[:, 1], \n",
    "        z=x_show[:, 2], \n",
    "        mode='markers',\n",
    "        marker={\n",
    "            'size': 10,\n",
    "            'opacity': 0.8,\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Configure the layout.\n",
    "    layout = go.Layout(\n",
    "        margin={'l': 0, 'r': 0, 'b': 0, 't': 0},\n",
    "        scene=Scene(\n",
    "                xaxis=XAxis(title=classes[i]),\n",
    "                yaxis=YAxis(title=classes[i]),\n",
    "                zaxis=ZAxis(title=classes[i])\n",
    "            )\n",
    "    )\n",
    "\n",
    "    data.append(trace)\n",
    "\n",
    "plot_figure = go.Figure(data=data, layout=layout)\n",
    "\n",
    "# Render the plot.\n",
    "plotly.offline.iplot(plot_figure)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggin_face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
